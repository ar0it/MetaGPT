{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "is_executing": true
   },
   "outputs": [],
   "source": "import openai\n"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "with open(\"raw_Metadata_Image8_full.txt\") as f:\n",
    "    metadata = f.read()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T15:50:17.938096135Z",
     "start_time": "2023-06-29T15:50:17.894284593Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Please transcribe the following metadata such that it follows the latest ome xml schema.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Sure, please provide the raw metadata such that I can transcribe it.\"},\n",
    "    {\"role\": \"user\", \"content\": metadata}\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T15:50:21.643962691Z",
     "start_time": "2023-06-29T15:50:21.642172194Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the transcribed metadata following the latest OME XML schema:\n",
      "\n",
      "```xml\n",
      "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
      "<OME xmlns=\"http://www.openmicroscopy.org/Schemas/OME/2016-06\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.openmicroscopy.org/Schemas/OME/2016-06 http://www.openmicroscopy.org/Schemas/OME/2016-06/ome.xsd\">\n",
      "  <Image ID=\"Image_8\">\n",
      "    <Pixels BigEndian=\"false\" DimensionOrder=\"XYCZT\" Interleaved=\"false\" PixelType=\"uint8\" SizeC=\"3\" SizeT=\"30\" SizeX=\"680\" SizeY=\"280\" SizeZ=\"1\">\n",
      "      <Channel ID=\"Channel_1\" SamplesPerPixel=\"1\">\n",
      "        <LightPath>\n",
      "          <IlluminationChannel ID=\"IlluminationChannel_1\">\n",
      "            <LightSourceRef ID=\"LightSource_1\"/>\n",
      "            <DetectorRef ID=\"Detector_1\"/>\n",
      "          </IlluminationChannel>\n",
      "        </LightPath>\n",
      "      </Channel>\n",
      "      <Channel ID=\"Channel_2\" SamplesPerPixel=\"1\">\n",
      "        <LightPath>\n",
      "          <IlluminationChannel ID=\"IlluminationChannel_2\">\n",
      "            <LightSourceRef ID=\"LightSource_2\"/>\n",
      "            <DetectorRef ID=\"Detector_2\"/>\n",
      "          </IlluminationChannel>\n",
      "        </LightPath>\n",
      "      </Channel>\n",
      "      <Channel ID=\"Channel_3\" SamplesPerPixel=\"1\">\n",
      "        <LightPath>\n",
      "          <IlluminationChannel ID=\"IlluminationChannel_3\">\n",
      "            <LightSourceRef ID=\"LightSource_3\"/>\n",
      "            <DetectorRef ID=\"Detector_3\"/>\n",
      "          </IlluminationChannel>\n",
      "        </LightPath>\n",
      "      </Channel>\n",
      "    </Pixels>\n",
      "  </Image>\n",
      "  <Instrument ID=\"Instrument_0\">\n",
      "    <Microscope ID=\"Microscope_0\" Manufacturer=\"Unknown\" Model=\"LSM 880, AxioObserver\">\n",
      "      <Objective ID=\"Objective_0\" Manufacturer=\"Unknown\" Model=\"C-Apochromat 63x/1.2 W Korr M27\" Immersion=\"Water\" LensNA=\"1.2000000000000002\" NominalMagnification=\"63\"/>\n",
      "    </Microscope>\n",
      "    <Detector ID=\"Detector_1\" AmplificationGain=\"2\" Gain=\"1\" Zoom=\"1\"/>\n",
      "    <Detector ID=\"Detector_2\" AmplificationGain=\"1\" Gain=\"1\" Zoom=\"1\"/>\n",
      "    <Detector ID=\"Detector_3\" AmplificationGain=\"2\" Gain=\"1\" Zoom=\"1\"/>\n",
      "    <LightSource ID=\"LightSource_1\" Manufacturer=\"Unknown\" Model=\"HeNe633\" Power=\"5\"/>\n",
      "    <LightSource ID=\"LightSource_2\" Manufacturer=\"Unknown\" Model=\"DPSS 561-10\" Power=\"20\"/>\n",
      "    <LightSource ID=\"LightSource_3\" Manufacturer=\"Unknown\" Model=\"Diode 405-30\" Power=\"30\"/>\n",
      "  </Instrument>\n",
      "  <Experiment ID=\"Experiment_0\">\n",
      "    <Acquisition ID=\"Acquisition_0\">\n",
      "      <Channel ID=\"Channel_1\" AcquisitionMode=\"LaserScanningConfocalMicroscopy\" Attenuation=\"0.95999999999999996\" Binning=\"1x1\" ChannelType=\"Unspecified\" ContrastMethod=\"Fluorescence\" DetectionWavelength=\"597.38843700000018-695.50278300000025\" DigitalGain=\"2\" EmissionWavelength=\"646.4456100000001\" ExcitationWavelength=\"561\" Fluor=\"mRFP1.2\" Gain=\"800\" IlluminationType=\"Epifluorescence\" LaserScanInfo_Averaging=\"2\" LaserScanInfo_FrameTime=\"8.922918787878789\" LaserScanInfo_LineTime=\"2.4242424242424244e-007\" LaserScanInfo_PixelTime=\"3.1060606060606059e-006\" LaserScanInfo_SampleOffsetX=\"6.6760282735367915e-006\" LaserScanInfo_SampleOffsetY=\"7.1528874358965848e-007\" LaserScanInfo_SampleRotation=\"-85.581379535589718\" LaserScanInfo_ScanningMode=\"LineSequential\" LaserScanInfo_ZoomX=\"2\" LaserScanInfo_ZoomY=\"2\" LightSourceRef=\"LightSource_1\" DetectorRef=\"Detector_1\"/>\n",
      "      <Channel ID=\"Channel_2\" AcquisitionMode=\"LaserScanningConfocalMicroscopy\" Attenuation=\"0.95999999999999996\" Binning=\"1x1\" ChannelType=\"Unspecified\" ContrastMethod=\"Other\" DetectionWavelength=\"499.27409100000017-561.71049300000027\" DigitalGain=\"1\" EmissionWavelength=\"530.49229200000025\" ExcitationWavelength=\"488.00000000000006\" Fluor=\"EGFP\" Gain=\"242.27363180139324\" IlluminationType=\"Epifluorescence\" LaserScanInfo_Averaging=\"2\" LaserScanInfo_FrameTime=\"8.922918787878789\" LaserScanInfo_LineTime=\"2.4242424242424244e-007\" LaserScanInfo_PixelTime=\"3.1060606060606059e-006\" LaserScanInfo_SampleOffsetX=\"6.6760282735367915e-006\" LaserScanInfo_SampleOffsetY=\"7.1528874358965848e-007\" LaserScanInfo_SampleRotation=\"-85.581379535589718\" LaserScanInfo_ScanningMode=\"LineSequential\" LaserScanInfo_ZoomX=\"2\" LaserScanInfo_ZoomY=\"2\" LightSourceRef=\"LightSource_2\" DetectorRef=\"Detector_2\"/>\n",
      "      <Channel ID=\"Channel_3\" AcquisitionMode=\"LaserScanningConfocalMicroscopy\" Attenuation=\"0.92999999999999994\" Binning=\"1x1\" ChannelType=\"Unspecified\" ContrastMethod=\"Fluorescence\" DetectionWavelength=\"499.27409100000017-561.71049300000027\" DigitalGain=\"2\" EmissionWavelength=\"530.49229200000025\" ExcitationWavelength=\"488.00000000000006\" Fluor=\"EGFP\" Gain=\"800\" IlluminationType=\"Epifluorescence\" LaserScanInfo_Averaging=\"2\" LaserScanInfo_FrameTime=\"8.922918787878789\" LaserScanInfo_LineTime=\"2.4242424242424244e-007\" LaserScanInfo_PixelTime=\"3.1060606060606059e-006\" LaserScanInfo_SampleOffsetX=\"6.6760282735367915e-006\" LaserScanInfo_SampleOffsetY=\"7.1528874358965848e-007\" LaserScanInfo_SampleRotation=\"-85.581379535589718\" LaserScanInfo_ScanningMode=\"LineSequential\" LaserScanInfo_ZoomX=\"2\" LaserScanInfo_ZoomY=\"2\" LightSourceRef=\"LightSource_3\" DetectorRef=\"Detector_3\"/>\n",
      "    </Acquisition>\n",
      "  </Experiment>\n",
      "</OME>\n",
      "```\n",
      "\n",
      "Please note that this is a simplified version of the metadata, and you may need to add additional elements or attributes based on your specific requirements.\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo-16k\",\n",
    "    messages=messages,\n",
    "    temperature=0,\n",
    "    max_tokens=5000,\n",
    "    top_p=1.0,\n",
    "    frequency_penalty=0.0,\n",
    "    presence_penalty=0.0,\n",
    "    stop=[\"\\\"\\\"\\\"\"]\n",
    ")\n",
    "print(response[\"choices\"][0][\"message\"][\"content\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T15:52:20.920437187Z",
     "start_time": "2023-06-29T15:51:33.148370703Z"
    }
   }
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T10:20:27.508835Z",
     "start_time": "2024-04-24T10:20:26.847478Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import instructor\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "client = instructor.patch(OpenAI())\n",
    "\n",
    "class UserDetail(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "    \n",
    "user = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    response_model=UserDetail,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Extract Aaron is 25 years old\"},\n",
    "    ],\n",
    ")\n",
    "assert isinstance(user, UserDetail)\n",
    "assert user.name == \"Aaron\"\n",
    "assert user.age == 25\n",
    "print(user.model_dump_json(indent=2))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"Aaron\",\n",
      "  \"age\": 25\n",
      "}\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T10:21:50.292928Z",
     "start_time": "2024-04-24T10:21:50.289962Z"
    }
   },
   "cell_type": "code",
   "source": "print(user._raw_response.model_dump_json(indent=2))",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-9HU1jwSUryakJkn3BflKfRzhwhfBZ\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"message\": {\n",
      "        \"content\": null,\n",
      "        \"role\": \"assistant\",\n",
      "        \"function_call\": null,\n",
      "        \"tool_calls\": [\n",
      "          {\n",
      "            \"id\": \"call_w4tRlHdD10JWUqfrBnLGasxT\",\n",
      "            \"function\": {\n",
      "              \"arguments\": \"{\\\"name\\\":\\\"Aaron\\\",\\\"age\\\":25}\",\n",
      "              \"name\": \"UserDetail\"\n",
      "            },\n",
      "            \"type\": \"function\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1713954027,\n",
      "  \"model\": \"gpt-3.5-turbo-0125\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"system_fingerprint\": \"fp_c2295e73ad\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 9,\n",
      "    \"prompt_tokens\": 81,\n",
      "    \"total_tokens\": 90\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T11:57:24.819218Z",
     "start_time": "2024-04-24T11:57:23.405787Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "import instructor\n",
    "\n",
    "# Apply the patch to the OpenAI client\n",
    "# enables response_model keyword\n",
    "client = instructor.patch(OpenAI())\n",
    "\n",
    "class QuestionAnswer(BaseModel):\n",
    "    question: str\n",
    "    answer: str\n",
    "\n",
    "question = \"What is the meaning of life?\"\n",
    "context = \"The according to the devil the meaning of live is to live a life of sin and debauchery.\"\n",
    "\n",
    "qa: QuestionAnswer = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    response_model=QuestionAnswer,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a system that answers questions based on the context. answer exactly what the question asks using the context.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"using the context: {context}\\n\\nAnswer the following question: {question}\",\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "print(qa.model_dump_json(indent=2))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"question\": \"What is the meaning of life?\",\n",
      "  \"answer\": \"According to the devil, the meaning of life is to live a life of sin and debauchery.\"\n",
      "}\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# LLM_Validator validation doesnt seem to work so well for me :("
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T11:58:48.469586Z",
     "start_time": "2024-04-24T11:58:46.052584Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pydantic import BaseModel, BeforeValidator\n",
    "from typing_extensions import Annotated\n",
    "from instructor import llm_validator\n",
    "\n",
    "class QuestionAnswerNoEvil(BaseModel):\n",
    "    question: str\n",
    "    answer: Annotated[\n",
    "        str,\n",
    "        BeforeValidator(\n",
    "            llm_validator(\"don't say objectionable things\",client=client, allow_override=True)\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "\n",
    "try:\n",
    "    qa: QuestionAnswerNoEvil = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        response_model=QuestionAnswerNoEvil,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a system that answers questions based on the context. answer exactly what the question asks using the context.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"using the context: {context}\\n\\nAnswer the following question: {question}\",\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "print(qa.model_dump_json(indent=2))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"question\": \"What is the meaning of life?\",\n",
      "  \"answer\": \"The meaning of life, according to the devil, is to live a life of sin and debauchery.\"\n",
      "}\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T13:31:05.598020Z",
     "start_time": "2024-04-24T13:31:05.589209Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import datetime\n",
    "from openai import OpenAI\n",
    "from typing import List\n",
    "from pydantic import Field\n",
    "from typing import Iterable, Optional\n",
    "\n",
    "client = instructor.patch(OpenAI(), mode=instructor.Mode.FUNCTIONS)\n"
   ],
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T13:45:43.323790Z",
     "start_time": "2024-04-24T13:45:43.209035Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Property(BaseModel):\n",
    "    index: str = Field(..., description=\"Monotonically increasing ID\")\n",
    "    key: str = Field(description=\"Must be snake case\")\n",
    "    value: str\n",
    "\n",
    "class Person(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "    birthday: datetime.date\n",
    "    properties: List[Property] = Field(\n",
    "        ...,\n",
    "        description=\"Numbered list of arbitrary extracted properties, should be exactly 2\"\n",
    "    )\n",
    "    \n",
    "class MaybePerson(BaseModel):\n",
    "    result: Optional[Person] = Field(default=None)\n",
    "    error: bool = Field(default=False)\n",
    "    message: Optional[str]\n",
    "    \n",
    "    \n",
    "schema = OME.model_json_schema()\n",
    "\n",
    "\n",
    "def extract(content):\n",
    "    return client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\",\n",
    "             \"content\": f\"Extract '{content}'\"}],\n",
    "        response_model=MaybePerson\n",
    "    )"
   ],
   "outputs": [],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T13:46:26.465946Z",
     "start_time": "2024-04-24T13:46:24.582491Z"
    }
   },
   "cell_type": "code",
   "source": [
    "content = f\"Aaron is 25 years old his birthday was yesterday today is {datetime.datetime}. He is friends with Caro whichs brithday was last week. They both like json.\"\n",
    "extract(content).model_dump()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'result': {'name': 'Aaron',\n",
       "  'age': 25,\n",
       "  'birthday': datetime.date(1997, 5, 12),\n",
       "  'properties': [{'index': '1', 'key': 'friends_with', 'value': 'Caro'}]},\n",
       " 'error': False,\n",
       " 'message': 'Extracted person information successfully.'}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 77
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

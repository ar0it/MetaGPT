{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "is_executing": true
   },
   "source": "import openai\n",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "with open(\"raw_Metadata_Image8_full.txt\") as f:\n",
    "    metadata = f.read()"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Please transcribe the following metadata such that it follows the latest ome xml schema.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Sure, please provide the raw metadata such that I can transcribe it.\"},\n",
    "    {\"role\": \"user\", \"content\": metadata}\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo-16k\",\n",
    "    messages=messages,\n",
    "    temperature=0,\n",
    "    max_tokens=5000,\n",
    "    top_p=1.0,\n",
    "    frequency_penalty=0.0,\n",
    "    presence_penalty=0.0,\n",
    "    stop=[\"\\\"\\\"\\\"\"]\n",
    ")\n",
    "print(response[\"choices\"][0][\"message\"][\"content\"])"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import instructor\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "client = instructor.patch(OpenAI())\n",
    "\n",
    "class UserDetail(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "    \n",
    "user = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    response_model=UserDetail,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Extract Aaron is 25 years old\"},\n",
    "    ],\n",
    ")\n",
    "assert isinstance(user, UserDetail)\n",
    "assert user.name == \"Aaron\"\n",
    "assert user.age == 25\n",
    "print(user.model_dump_json(indent=2))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(user._raw_response.model_dump_json(indent=2))",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "import instructor\n",
    "\n",
    "# Apply the patch to the OpenAI client\n",
    "# enables response_model keyword\n",
    "client = instructor.patch(OpenAI())\n",
    "\n",
    "class QuestionAnswer(BaseModel):\n",
    "    question: str\n",
    "    answer: str\n",
    "\n",
    "question = \"What is the meaning of life?\"\n",
    "context = \"The according to the devil the meaning of live is to live a life of sin and debauchery.\"\n",
    "\n",
    "qa: QuestionAnswer = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    response_model=QuestionAnswer,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a system that answers questions based on the context. answer exactly what the question asks using the context.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"using the context: {context}\\n\\nAnswer the following question: {question}\",\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "print(qa.model_dump_json(indent=2))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# LLM_Validator validation doesnt seem to work so well for me :("
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pydantic import BaseModel, BeforeValidator\n",
    "from typing_extensions import Annotated\n",
    "from instructor import llm_validator\n",
    "\n",
    "class QuestionAnswerNoEvil(BaseModel):\n",
    "    question: str\n",
    "    answer: Annotated[\n",
    "        str,\n",
    "        BeforeValidator(\n",
    "            llm_validator(\"don't say objectionable things\",client=client, allow_override=True)\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "\n",
    "try:\n",
    "    qa: QuestionAnswerNoEvil = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        response_model=QuestionAnswerNoEvil,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a system that answers questions based on the context. answer exactly what the question asks using the context.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"using the context: {context}\\n\\nAnswer the following question: {question}\",\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "print(qa.model_dump_json(indent=2))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import datetime\n",
    "from openai import OpenAI\n",
    "from typing import List\n",
    "from pydantic import Field\n",
    "from typing import Iterable, Optional\n",
    "import instructor\n",
    "\n",
    "client = instructor.patch(OpenAI(), mode=instructor.Mode.FUNCTIONS)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class Property(BaseModel):\n",
    "    index: str = Field(..., description=\"Monotonically increasing ID\")\n",
    "    key: str = Field(description=\"Must be snake case\")\n",
    "    value: str\n",
    "\n",
    "class Person(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "    birthday: datetime.date\n",
    "    properties: List[Property] = Field(\n",
    "        ...,\n",
    "        description=\"Numbered list of arbitrary extracted properties, should be exactly 2\"\n",
    "    )\n",
    "    \n",
    "class MaybePerson(BaseModel):\n",
    "    result: Optional[Person] = Field(default=None)\n",
    "    error: bool = Field(default=False)\n",
    "    message: Optional[str]\n",
    "    \n",
    "    \n",
    "schema = MaybePerson.model_json_schema()\n",
    "\n",
    "\n",
    "def extract(content):\n",
    "    return client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\",\n",
    "             \"content\": f\"Extract '{content}'\"}],\n",
    "        response_model=MaybePerson\n",
    "    )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "content = f\"Aaron is 25 years old his birthday was yesterday today is {datetime.datetime}. He is friends with Caro whichs brithday was last week. They both like json.\"\n",
    "extract(content).model_dump()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "content = (f'Today is {datetime.datetime}, yesterday Aaron did a lighsheet microscopy experiment with the following metadata. <Image ID=\"Image:0\" Name=\"Image 8 #1\">'\n",
    "           '<Pixels BigEndian=\"false\" DimensionOrder=\"XYCZT\"'\n",
    "           'ID=\"Pixels:0\"'\n",
    "           'PhysicalSizeX=\"0.0992287815904495\"'\n",
    "           'PhysicalSizeXUnit=\"µm\"'\n",
    "           'PhysicalSizeY=\"0.0992287815904495\"'\n",
    "           'PhysicalSizeYUnit=\"µm\"'\n",
    "           'SignificantBits=\"8\"'\n",
    "           'SizeC=\"3\"'\n",
    "           'SizeT=\"30\"'\n",
    "           'SizeX=\"680\"'\n",
    "           'SizeY=\"280\"'\n",
    "           'SizeZ=\"1\"'\n",
    "           'Type=\"uint8\">'\n",
    "           '<Channel AcquisitionMode=\"LaserScanningConfocalMicroscopy\" Color=\"-16711681\" EmissionWavelength=\"646.4456100000001\" EmissionWavelengthUnit=\"nm\" ExcitationWavelength=\"561.0\" ExcitationWavelengthUnit=\"nm\" Fluor=\"mRFP1.2\" ID=\"Channel:0:0\" IlluminationType=\"Epifluorescence\" Name=\"ChS2-T1\" SamplesPerPixel=\"1\">'\n",
    "           '<DetectorSettings Binning=\"1x1\" ID=\"Detector:0:0\"/>'\n",
    "           '<LightPath/>'\n",
    "           '</Channel>'\n",
    "           '<Channel AcquisitionMode=\"LaserScanningConfocalMicroscopy\" Color=\"-1\" ID=\"Channel:0:1\" IlluminationType=\"Epifluorescence\" Name=\"T PMT-T1\" SamplesPerPixel=\"1\">'\n",
    "           '<DetectorSettings Binning=\"1x1\" ID=\"Detector:0:1\"/>'\n",
    "           '<LightPath/>'\n",
    "           '</Channel>'\n",
    "           '<Channel AcquisitionMode=\"LaserScanningConfocalMicroscopy\" Color=\"16711935\" EmissionWavelength=\"530.4922920000002\" EmissionWavelengthUnit=\"nm\" ExcitationWavelength=\"488.00000000000006\" ExcitationWavelengthUnit=\"nm\" Fluor=\"EGFP\" ID=\"Channel:0:2\" IlluminationType=\"Epifluorescence\" Name=\"ChS1-T2\" SamplesPerPixel=\"1\">'\n",
    "           '<DetectorSettings Binning=\"1x1\" ID=\"Detector:1:0\"/>'\n",
    "           '<LightPath/>'\n",
    "           '</Channel>'\n",
    "           '<TiffData FirstC=\"0\" FirstT=\"0\" FirstZ=\"0\" IFD=\"0\" PlaneCount=\"1\">'\n",
    "           '<UUID FileName=\"testetst_Image8_edited_.ome.tif\">urn:uuid:27555393-9fb6-4c14-942c-badbf7548154</UUID>'\n",
    "           '</TiffData>'\n",
    "           '</Pixels>'\n",
    "           '</Image>')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from ome_types import OME\n",
    "type(OME)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from ome_types.model import Image\n",
    "from ome_types.model import Experiment\n",
    "from ome_types.model import Experimenter\n",
    "from ome_types.model import Annotation\n",
    "    \n",
    "    \n",
    "schema = OME.model_json_schema()\n",
    "print(schema)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def extract(content):\n",
    "    return client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\",\n",
    "             \"content\": f\"Extract the ome image'{content}'\"}],\n",
    "        response_model=OME\n",
    "    )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "from ome_types import OME",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from ome_types import OME\n",
    "print(type(OME))\n",
    "def extract(content):\n",
    "    return client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\",\n",
    "             \"content\": f\"Extract '{content}'\"}],\n",
    "        response_model=OME\n",
    "    )\n",
    "\n",
    "content= (\" BitsPerPixel\t8\"\n",
    "          \"DimensionOrder\tXYCZT\"\n",
    "          \"IsInterleaved\tfalse\"\n",
    "          \"IsRGB\tfalse\"\n",
    "          \"LittleEndian\ttrue\"\n",
    "          \"PixelType\tuint8\"\n",
    "          \"Series 0 Name\tImage 8 #1\"\n",
    "          \"SizeC\t3\"\n",
    "          \"SizeT\t30\"\n",
    "          \"SizeX\t680\"\n",
    "          \"SizeY\t280\"\n",
    "          \"SizeZ\t1\")\n",
    "\n",
    "extract(content).model_dump()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T20:30:19.023859Z",
     "start_time": "2024-05-02T20:30:18.959980Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Iterable, Optional\n",
    "import instructor\n",
    "from openai import OpenAI\n",
    "\n",
    "client = instructor.patch(OpenAI(), mode=instructor.Mode.FUNCTIONS)\n",
    "\n",
    "class Image(BaseModel):\n",
    "    id: str = Field(..., description=\"Unique identifier for the image\")\n",
    "    name: str = Field(..., description=\"Name of the image\")\n",
    "    \n",
    "class OME(BaseModel):\n",
    "    images: List[Image] = Field(..., description=\"List of images in the OME metadata\")\n",
    "\n",
    "print(OME.model_json_schema())\n",
    "class MaybeOME(BaseModel):\n",
    "    result: Optional[OME] = Field(default=None)\n",
    "    error: bool = Field(default=False)\n",
    "    message: Optional[str]\n",
    "    \n",
    "def extract(content):\n",
    "    return client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\",\n",
    "             \"content\": f\"Extract '{content}'\"}],\n",
    "        response_model=OME.model_json_schema()\n",
    "    )\n",
    "\n",
    "content= (\" BitsPerPixel\t8\"\n",
    "          \"DimensionOrder\tXYCZT\"\n",
    "          \"IsInterleaved\tfalse\"\n",
    "          \"IsRGB\tfalse\"\n",
    "          \"LittleEndian\ttrue\"\n",
    "          \"PixelType\tuint8\"\n",
    "          \"Series 0 Name\tImage 8 #1\"\n",
    "          \"SizeC\t3\"\n",
    "          \"SizeT\t30\"\n",
    "          \"SizeX\t680\"\n",
    "          \"SizeY\t280\"\n",
    "          \"SizeZ\t1\")\n",
    "\n",
    "extract(content).model_dump()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'$defs': {'Image': {'properties': {'id': {'description': 'Unique identifier for the image', 'title': 'Id', 'type': 'string'}, 'name': {'description': 'Name of the image', 'title': 'Name', 'type': 'string'}}, 'required': ['id', 'name'], 'title': 'Image', 'type': 'object'}}, 'properties': {'images': {'description': 'List of images in the OME metadata', 'items': {'$ref': '#/$defs/Image'}, 'title': 'Images', 'type': 'array'}}, 'required': ['images'], 'title': 'OME', 'type': 'object'}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[14], line 43\u001B[0m\n\u001B[1;32m     22\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m client\u001B[38;5;241m.\u001B[39mchat\u001B[38;5;241m.\u001B[39mcompletions\u001B[38;5;241m.\u001B[39mcreate(\n\u001B[1;32m     23\u001B[0m         model\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgpt-3.5-turbo\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     24\u001B[0m         messages\u001B[38;5;241m=\u001B[39m[\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     27\u001B[0m         response_model\u001B[38;5;241m=\u001B[39mOME\u001B[38;5;241m.\u001B[39mmodel_json_schema()\n\u001B[1;32m     28\u001B[0m     )\n\u001B[1;32m     30\u001B[0m content\u001B[38;5;241m=\u001B[39m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m BitsPerPixel\t8\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     31\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDimensionOrder\tXYCZT\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     32\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIsInterleaved\tfalse\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     40\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSizeY\t280\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     41\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSizeZ\t1\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 43\u001B[0m extract(content)\u001B[38;5;241m.\u001B[39mmodel_dump()\n",
      "Cell \u001B[0;32mIn[14], line 22\u001B[0m, in \u001B[0;36mextract\u001B[0;34m(content)\u001B[0m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mextract\u001B[39m(content):\n\u001B[0;32m---> 22\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m client\u001B[38;5;241m.\u001B[39mchat\u001B[38;5;241m.\u001B[39mcompletions\u001B[38;5;241m.\u001B[39mcreate(\n\u001B[1;32m     23\u001B[0m         model\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgpt-3.5-turbo\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     24\u001B[0m         messages\u001B[38;5;241m=\u001B[39m[\n\u001B[1;32m     25\u001B[0m             {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrole\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muser\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     26\u001B[0m              \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontent\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExtract \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcontent\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m}],\n\u001B[1;32m     27\u001B[0m         response_model\u001B[38;5;241m=\u001B[39mOME\u001B[38;5;241m.\u001B[39mmodel_json_schema()\n\u001B[1;32m     28\u001B[0m     )\n",
      "File \u001B[0;32m~/mambaforge/envs/metagpt/lib/python3.12/site-packages/instructor/patch.py:140\u001B[0m, in \u001B[0;36mpatch.<locals>.new_create_sync\u001B[0;34m(response_model, validation_context, max_retries, strict, *args, **kwargs)\u001B[0m\n\u001B[1;32m    131\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(func)\n\u001B[1;32m    132\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mnew_create_sync\u001B[39m(\n\u001B[1;32m    133\u001B[0m     response_model: \u001B[38;5;28mtype\u001B[39m[T_Model] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    138\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: T_ParamSpec\u001B[38;5;241m.\u001B[39mkwargs,\n\u001B[1;32m    139\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m T_Model:\n\u001B[0;32m--> 140\u001B[0m     response_model, new_kwargs \u001B[38;5;241m=\u001B[39m handle_response_model(\n\u001B[1;32m    141\u001B[0m         response_model\u001B[38;5;241m=\u001B[39mresponse_model, mode\u001B[38;5;241m=\u001B[39mmode, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[1;32m    142\u001B[0m     )\n\u001B[1;32m    143\u001B[0m     response \u001B[38;5;241m=\u001B[39m retry_sync(\n\u001B[1;32m    144\u001B[0m         func\u001B[38;5;241m=\u001B[39mfunc,\n\u001B[1;32m    145\u001B[0m         response_model\u001B[38;5;241m=\u001B[39mresponse_model,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    151\u001B[0m         mode\u001B[38;5;241m=\u001B[39mmode,\n\u001B[1;32m    152\u001B[0m     )\n\u001B[1;32m    153\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m response\n",
      "File \u001B[0;32m~/mambaforge/envs/metagpt/lib/python3.12/site-packages/instructor/process_response.py:191\u001B[0m, in \u001B[0;36mhandle_response_model\u001B[0;34m(response_model, mode, **kwargs)\u001B[0m\n\u001B[1;32m    186\u001B[0m new_kwargs \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mcopy()\n\u001B[1;32m    187\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m response_model \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    188\u001B[0m     \u001B[38;5;66;03m# Handles the case where the response_model is a simple type\u001B[39;00m\n\u001B[1;32m    189\u001B[0m     \u001B[38;5;66;03m# Literal, Annotated, Union, str, int, float, bool, Enum\u001B[39;00m\n\u001B[1;32m    190\u001B[0m     \u001B[38;5;66;03m# We wrap the response_model in a ModelAdapter that sets 'content' as the response\u001B[39;00m\n\u001B[0;32m--> 191\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m is_simple_type(response_model):\n\u001B[1;32m    192\u001B[0m         response_model \u001B[38;5;241m=\u001B[39m ModelAdapter[response_model]\n\u001B[1;32m    194\u001B[0m     \u001B[38;5;66;03m# This a special case for parallel tools\u001B[39;00m\n",
      "File \u001B[0;32m~/mambaforge/envs/metagpt/lib/python3.12/site-packages/instructor/dsl/simple_type.py:47\u001B[0m, in \u001B[0;36mis_simple_type\u001B[0;34m(response_model)\u001B[0m\n\u001B[1;32m     43\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m typing\u001B[38;5;241m.\u001B[39mget_origin(response_model) \u001B[38;5;129;01min\u001B[39;00m {typing\u001B[38;5;241m.\u001B[39mIterable, Partial}:\n\u001B[1;32m     44\u001B[0m     \u001B[38;5;66;03m# These are reserved for streaming types, would be nice to\u001B[39;00m\n\u001B[1;32m     45\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m---> 47\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m response_model \u001B[38;5;129;01min\u001B[39;00m {\n\u001B[1;32m     48\u001B[0m     \u001B[38;5;28mstr\u001B[39m,\n\u001B[1;32m     49\u001B[0m     \u001B[38;5;28mint\u001B[39m,\n\u001B[1;32m     50\u001B[0m     \u001B[38;5;28mfloat\u001B[39m,\n\u001B[1;32m     51\u001B[0m     \u001B[38;5;28mbool\u001B[39m,\n\u001B[1;32m     52\u001B[0m }:\n\u001B[1;32m     53\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;66;03m# If the response_model is a simple type like annotated\u001B[39;00m\n",
      "\u001B[0;31mTypeError\u001B[0m: unhashable type: 'dict'"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from ome_types import from_xml\n",
    "from ome_types import to_xml\n",
    "from ome_types import to_dict\n",
    "path = \"/home/aaron/PycharmProjects/MetaGPT/raw_data/image8_start_point.ome.xml\"\n",
    "ome = from_xml(path)\n",
    "print(to_xml(ome))\n",
    "print(to_dict(ome))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from typing import List, Optional\n",
    "\n",
    "from pydantic_compat import field_validator\n",
    "\n",
    "from ome_types._autogenerated.ome_2016_06.dataset import Dataset\n",
    "from ome_types._autogenerated.ome_2016_06.experiment import Experiment\n",
    "from ome_types._autogenerated.ome_2016_06.experimenter import Experimenter\n",
    "from ome_types._autogenerated.ome_2016_06.experimenter_group import (\n",
    "    ExperimenterGroup,\n",
    ")\n",
    "from ome_types._autogenerated.ome_2016_06.folder import Folder\n",
    "from ome_types._autogenerated.ome_2016_06.image import Image\n",
    "from ome_types._autogenerated.ome_2016_06.instrument import Instrument\n",
    "from ome_types._autogenerated.ome_2016_06.plate import Plate\n",
    "from ome_types._autogenerated.ome_2016_06.project import Project\n",
    "from ome_types._autogenerated.ome_2016_06.rights import Rights\n",
    "from ome_types._autogenerated.ome_2016_06.roi import ROI\n",
    "from ome_types._autogenerated.ome_2016_06.screen import Screen\n",
    "from ome_types._autogenerated.ome_2016_06.structured_annotations import (\n",
    "    StructuredAnnotations,\n",
    ")\n",
    "from ome_types._mixins._base_type import OMEType\n",
    "from ome_types._mixins._ome import OMEMixin\n",
    "#from ome_types._mixins._validators import validate_structured_annotations\n",
    "from xsdata_pydantic_basemodel.pydantic_compat import Field\n",
    "\n",
    "__NAMESPACE__ = \"http://www.openmicroscopy.org/Schemas/OME/2016-06\"\n",
    "\n",
    "\n",
    "class OME(OMEMixin, OMEType):\n",
    "    \"\"\"The OME element is a container for all information objects accessible by\n",
    "    OME.\n",
    "\n",
    "    These information objects include descriptions of the imaging experiments\n",
    "    and the people who perform them, descriptions of the microscope, the resulting\n",
    "    images and how they were acquired, the analyses performed on those images,\n",
    "    and the analysis results themselves.\n",
    "    An OME file may contain any or all of this information.\n",
    "    With the creation of the Metadata Only Companion OME-XML and Binary Only OME-TIFF files\n",
    "    the top level OME node has changed slightly.\n",
    "    It can EITHER:\n",
    "    Contain all the previously expected elements\n",
    "    OR:\n",
    "    Contain a single BinaryOnly element that points at\n",
    "    its Metadata Only Companion OME-XML file.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    rights : None | Rights\n",
    "        (The OME Rights).\n",
    "    projects : list[Project]\n",
    "        (The OME Projects).\n",
    "    datasets : list[Dataset]\n",
    "        (The OME Datasets).\n",
    "    folders : list[Folder]\n",
    "        (The OME Folders).\n",
    "    experiments : list[Experiment]\n",
    "        (The OME Experiments).\n",
    "    plates : list[Plate]\n",
    "        (The OME Plates).\n",
    "    screens : list[Screen]\n",
    "        (The OME Screens).\n",
    "    experimenters : list[Experimenter]\n",
    "        (The OME Experimenters).\n",
    "    experimenter_groups : list[ExperimenterGroup]\n",
    "        (The OME ExperimenterGroups).\n",
    "    instruments : list[Instrument]\n",
    "        (The OME Instruments).\n",
    "    images : list[Image]\n",
    "        (The OME Images).\n",
    "    structured_annotations : None | StructuredAnnotations\n",
    "        (The OME StructuredAnnotations).\n",
    "    rois : list[ROI]\n",
    "        (The OME ROIs).\n",
    "    binary_only : None | \"OME.BinaryOnly\"\n",
    "        Pointer to an external metadata file. If this element is present, then no\n",
    "        other metadata may be present in this file, i.e. this file is a place-\n",
    "        holder.\n",
    "    uuid : None | str\n",
    "        This unique identifier is used to keep track of multi part files. It allows\n",
    "        the links between files to survive renaming. While OPTIONAL in the general\n",
    "        case this is REQUIRED in a MetadataOnly Companion to a collection of\n",
    "        BinaryOnly files.\n",
    "    creator : None | str\n",
    "        This is the name of the creating application of the OME-XML and preferably\n",
    "        its full version. e.g \"CompanyName, SoftwareName, V2.6.3456\" This is\n",
    "        optional but we hope it will be set by applications writing out OME-XML\n",
    "        from scratch.\n",
    "    \"\"\"\n",
    "\n",
    "    class Meta:\n",
    "        namespace = \"http://www.openmicroscopy.org/Schemas/OME/2016-06\"\n",
    "\n",
    "    rights: Optional[Rights] = Field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"name\": \"Rights\",\n",
    "            \"type\": \"Element\",\n",
    "        },\n",
    "    )\n",
    "    projects: List[Project] = Field(\n",
    "        default_factory=list,\n",
    "        metadata={\n",
    "            \"name\": \"Project\",\n",
    "            \"type\": \"Element\",\n",
    "        },\n",
    "    )\n",
    "    datasets: List[Dataset] = Field(\n",
    "        default_factory=list,\n",
    "        metadata={\n",
    "            \"name\": \"Dataset\",\n",
    "            \"type\": \"Element\",\n",
    "        },\n",
    "    )\n",
    "    folders: List[Folder] = Field(\n",
    "        default_factory=list,\n",
    "        metadata={\n",
    "            \"name\": \"Folder\",\n",
    "            \"type\": \"Element\",\n",
    "        },\n",
    "    )\n",
    "    experiments: List[Experiment] = Field(\n",
    "        default_factory=list,\n",
    "        metadata={\n",
    "            \"name\": \"Experiment\",\n",
    "            \"type\": \"Element\",\n",
    "        },\n",
    "    )\n",
    "    plates: List[Plate] = Field(\n",
    "        default_factory=list,\n",
    "        metadata={\n",
    "            \"name\": \"Plate\",\n",
    "            \"type\": \"Element\",\n",
    "        },\n",
    "    )\n",
    "    screens: List[Screen] = Field(\n",
    "        default_factory=list,\n",
    "        metadata={\n",
    "            \"name\": \"Screen\",\n",
    "            \"type\": \"Element\",\n",
    "        },\n",
    "    )\n",
    "    experimenters: List[Experimenter] = Field(\n",
    "        default_factory=list,\n",
    "        metadata={\n",
    "            \"name\": \"Experimenter\",\n",
    "            \"type\": \"Element\",\n",
    "        },\n",
    "    )\n",
    "    experimenter_groups: List[ExperimenterGroup] = Field(\n",
    "        default_factory=list,\n",
    "        metadata={\n",
    "            \"name\": \"ExperimenterGroup\",\n",
    "            \"type\": \"Element\",\n",
    "        },\n",
    "    )\n",
    "    instruments: List[Instrument] = Field(\n",
    "        default_factory=list,\n",
    "        metadata={\n",
    "            \"name\": \"Instrument\",\n",
    "            \"type\": \"Element\",\n",
    "        },\n",
    "    )\n",
    "    images: List[Image] = Field(\n",
    "        default_factory=list,\n",
    "        metadata={\n",
    "            \"name\": \"Image\",\n",
    "            \"type\": \"Element\",\n",
    "        },\n",
    "    )\n",
    "    structured_annotations: Optional[StructuredAnnotations] = Field(\n",
    "        metadata={\n",
    "            \"name\": \"StructuredAnnotations\",\n",
    "            \"type\": \"Element\",\n",
    "        },\n",
    "        default_factory=StructuredAnnotations,\n",
    "    )\n",
    "    # FIXME: THIS IS THE PROBLEM TypeError: unhashable type: 'dict'\n",
    "    rois: List[ROI] = Field(\n",
    "        default_factory=list,\n",
    "        metadata={\n",
    "            \"name\": \"ROI\",\n",
    "            \"type\": \"Element\",\n",
    "        },\n",
    "    )\n",
    "    binary_only: Optional[\"OME.BinaryOnly\"] = Field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"name\": \"BinaryOnly\",\n",
    "            \"type\": \"Element\",\n",
    "        },\n",
    "    )\n",
    "    uuid: Optional[str] = Field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"name\": \"UUID\",\n",
    "            \"type\": \"Attribute\",\n",
    "            \"pattern\": r\"(urn:uuid:[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{12})\",\n",
    "        },\n",
    "        regex=\"(urn:uuid:[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{12})\",\n",
    "    )\n",
    "    creator: Optional[str] = Field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"name\": \"Creator\",\n",
    "            \"type\": \"Attribute\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "    class BinaryOnly(OMEType):\n",
    "        \"\"\"\n",
    "        Attributes\n",
    "        ----------\n",
    "        metadata_file : str\n",
    "            Filename of the OME-XML metadata file for this binary data. If the file\n",
    "            cannot be found, a search can be performed based on the UUID.\n",
    "        uuid : str\n",
    "            The unique identifier of another OME-XML block whose metadata describes the\n",
    "            binary data in this file. This UUID is considered authoritative regardless\n",
    "            of mismatches in the filename.\n",
    "        \"\"\"\n",
    "\n",
    "        metadata_file: str = Field(\n",
    "            metadata={\n",
    "                \"name\": \"MetadataFile\",\n",
    "                \"type\": \"Attribute\",\n",
    "                \"required\": True,\n",
    "            }\n",
    "        )\n",
    "        uuid: str = Field(\n",
    "            metadata={\n",
    "                \"name\": \"UUID\",\n",
    "                \"type\": \"Attribute\",\n",
    "                \"required\": True,\n",
    "                \"pattern\": r\"(urn:uuid:[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{12})\",\n",
    "            },\n",
    "            regex=\"(urn:uuid:[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{12})\",\n",
    "        )\n",
    "\n",
    "    #_v_structured_annotations = field_validator(\n",
    "    #    \"structured_annotations\", mode=\"before\"\n",
    "    #)(validate_structured_annotations)\n",
    "\n",
    "\n",
    "BinaryOnly = OME.BinaryOnly\n",
    "\n",
    "OME.model_json_schema()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:37:06.290698Z",
     "start_time": "2024-05-02T19:37:06.269808Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import List, Optional\n",
    "\n",
    "from pydantic_compat import field_validator\n",
    "\n",
    "from ome_types._autogenerated.ome_2016_06.annotation_ref import AnnotationRef\n",
    "from ome_types._autogenerated.ome_2016_06.ellipse import Ellipse\n",
    "from ome_types._autogenerated.ome_2016_06.label import Label\n",
    "from ome_types._autogenerated.ome_2016_06.line import Line\n",
    "from ome_types._autogenerated.ome_2016_06.mask import Mask\n",
    "from ome_types._autogenerated.ome_2016_06.point import Point\n",
    "from ome_types._autogenerated.ome_2016_06.polygon import Polygon\n",
    "from ome_types._autogenerated.ome_2016_06.polyline import Polyline\n",
    "from ome_types._autogenerated.ome_2016_06.rectangle import Rectangle\n",
    "from ome_types._mixins._base_type import OMEType\n",
    "from ome_types._mixins._collections import ShapeUnionMixin\n",
    "from ome_types._mixins._validators import validate_shape_union\n",
    "from xsdata_pydantic_basemodel.pydantic_compat import Field\n",
    "\n",
    "__NAMESPACE__ = \"http://www.openmicroscopy.org/Schemas/OME/2016-06\"\n",
    "\n",
    "\n",
    "class ROI(OMEType):\n",
    "    \"\"\"A four dimensional 'Region of Interest'.\n",
    "\n",
    "    If they are not used, and the Image has more than one plane, the\n",
    "    entire set of planes is assumed to be included in the ROI. Multiple\n",
    "    ROIs may be specified.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    union : \"ROI.Union\"\n",
    "        (The ROI Union).\n",
    "    annotation_refs : list[AnnotationRef]\n",
    "        (The ROI AnnotationRefs).\n",
    "    description : None | str\n",
    "        A description for the ROI. [plain-text multi-line string]\n",
    "    id : str\n",
    "        (The ROI ID).\n",
    "    name : None | str\n",
    "        The Name identifies the ROI to the user. [plain-text string]\n",
    "    \"\"\"\n",
    "\n",
    "    class Meta:\n",
    "        namespace = \"http://www.openmicroscopy.org/Schemas/OME/2016-06\"\n",
    "\n",
    "    union: \"ROI.Union\" = Field(\n",
    "        metadata={\n",
    "            \"name\": \"Union\",\n",
    "            \"type\": \"Element\",\n",
    "            \"required\": True,\n",
    "        },\n",
    "        default_factory=lambda: ROI.Union(),\n",
    "    )\n",
    "    annotation_refs: List[AnnotationRef] = Field(\n",
    "        default_factory=list,\n",
    "        metadata={\n",
    "            \"name\": \"AnnotationRef\",\n",
    "            \"type\": \"Element\",\n",
    "        },\n",
    "    )\n",
    "    description: Optional[str] = Field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"name\": \"Description\",\n",
    "            \"type\": \"Element\",\n",
    "            \"white_space\": \"preserve\",\n",
    "        },\n",
    "    )\n",
    "    id: str = Field(\n",
    "        default=\"__auto_sequence__\",\n",
    "        metadata={\n",
    "            \"name\": \"ID\",\n",
    "            \"type\": \"Attribute\",\n",
    "            \"required\": True,\n",
    "            \"pattern\": r\"(urn:lsid:([\\w\\-\\.]+\\.[\\w\\-\\.]+)+:\\S+)|(\\S+)\",\n",
    "        },\n",
    "        regex=\"(urn:lsid:([\\\\w\\\\-\\\\.]+\\\\.[\\\\w\\\\-\\\\.]+)+:\\\\S+)|(\\\\S+)\",\n",
    "    )\n",
    "    name: Optional[str] = Field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"name\": \"Name\",\n",
    "            \"type\": \"Attribute\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "    class Union(ShapeUnionMixin, OMEType):\n",
    "        labels: List[Label] = Field(\n",
    "            default_factory=list,\n",
    "            metadata={\n",
    "                \"name\": \"Label\",\n",
    "                \"type\": \"Element\",\n",
    "            },\n",
    "        )\n",
    "        polygons: List[Polygon] = Field(\n",
    "            default_factory=list,\n",
    "            metadata={\n",
    "                \"name\": \"Polygon\",\n",
    "                \"type\": \"Element\",\n",
    "            },\n",
    "        )\n",
    "        polylines: List[Polyline] = Field(\n",
    "            default_factory=list,\n",
    "            metadata={\n",
    "                \"name\": \"Polyline\",\n",
    "                \"type\": \"Element\",\n",
    "            },\n",
    "        )\n",
    "        lines: List[Line] = Field(\n",
    "            default_factory=list,\n",
    "            metadata={\n",
    "                \"name\": \"Line\",\n",
    "                \"type\": \"Element\",\n",
    "            },\n",
    "        )\n",
    "        ellipses: List[Ellipse] = Field(\n",
    "            default_factory=list,\n",
    "            metadata={\n",
    "                \"name\": \"Ellipse\",\n",
    "                \"type\": \"Element\",\n",
    "            },\n",
    "        )\n",
    "        points: List[Point] = Field(\n",
    "            default_factory=list,\n",
    "            metadata={\n",
    "                \"name\": \"Point\",\n",
    "                \"type\": \"Element\",\n",
    "            },\n",
    "        )\n",
    "        masks: List[Mask] = Field(\n",
    "            default_factory=list,\n",
    "            metadata={\n",
    "                \"name\": \"Mask\",\n",
    "                \"type\": \"Element\",\n",
    "            },\n",
    "        )\n",
    "        rectangles: List[Rectangle] = Field(\n",
    "            default_factory=list,\n",
    "            metadata={\n",
    "                \"name\": \"Rectangle\",\n",
    "                \"type\": \"Element\",\n",
    "            },\n",
    "        )\n",
    "\n",
    "    #_v_shape_union = field_validator(\"union\", mode=\"before\")(validate_shape_union)\n",
    "\n",
    "\n",
    "Union = ROI.Union\n",
    "\n",
    "\n",
    "schema = ROI.model_json_schema()\n",
    "print(schema)"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ome_types._mixins._collections'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[68], line 15\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mome_types\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_autogenerated\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mome_2016_06\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mrectangle\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Rectangle\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mome_types\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_mixins\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_base_type\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m OMEType\n\u001B[0;32m---> 15\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mome_types\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_mixins\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_collections\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ShapeUnionMixin\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mome_types\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_mixins\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_validators\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m validate_shape_union\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mxsdata_pydantic_basemodel\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpydantic_compat\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Field\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'ome_types._mixins._collections'"
     ]
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T20:28:20.562166Z",
     "start_time": "2024-05-02T20:28:20.444896Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from ome_types._autogenerated.ome_2016_06 import OME\n",
    "import json\n",
    "\n",
    "schema = OME.model_json_schema()\n",
    "\n",
    "with open('schema.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(schema, f, ensure_ascii=False, indent=4)"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:59:25.605684Z",
     "start_time": "2024-05-02T19:59:24.117300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from ome_types._autogenerated.ome_2016_06 import OME\n",
    "from openai import OpenAI\n",
    "import instructor\n",
    "\n",
    "\n",
    "client = instructor.patch(OpenAI())\n",
    "with open(\"/home/aaron/PycharmProjects/MetaGPT/raw_data/raw_Metadata_Image8.txt\") as f:\n",
    "    input = f.read()\n",
    "    print(input)\n",
    "    \n",
    "def extract(content):\n",
    "    return client.chat.completions.create(\n",
    "        model=\"gpt-4-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\",\n",
    "             \"content\": f\"Please genearate the appropriate omexml from this raw metadata. '{input}'\"}],\n",
    "        response_model=OME,\n",
    "        max_tokens=5000\n",
    "    )\n",
    "\n",
    "extract(input).model_dump()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " BitsPerPixel\t8\n",
      " DimensionOrder\tXYCZT\n",
      " IsInterleaved\tfalse\n",
      " IsRGB\tfalse\n",
      " LittleEndian\ttrue\n",
      " PixelType\tuint8\n",
      " Series 0 Name\tImage 8 #1\n",
      " SizeC\t3\n",
      " SizeT\t30\n",
      " SizeX\t680\n",
      " SizeY\t280\n",
      " SizeZ\t1\n",
      "Appliance|Data|ShuttleAndFindData|Calibration|Marker|FocusPosition #1\t0\n",
      "Appliance|Data|ShuttleAndFindData|Calibration|Marker|FocusPosition #2\t0\n",
      "Appliance|Data|ShuttleAndFindData|Calibration|Marker|FocusPosition #3\t0\n",
      "Appliance|Data|ShuttleAndFindData|Calibration|Marker|Id #1\tMarker:1\n",
      "Appliance|Data|ShuttleAndFindData|Calibration|Marker|Id #2\tMarker:2\n",
      "Appliance|Data|ShuttleAndFindData|Calibration|Marker|Id #3\tMarker:3\n",
      "Appliance|Data|ShuttleAndFindData|Calibration|Marker|StageXPosition #1\t0\n",
      "Appliance|Data|ShuttleAndFindData|Calibration|Marker|StageXPosition #2\t0\n",
      "Appliance|Data|ShuttleAndFindData|Calibration|Marker|StageXPosition #3\t0\n",
      "Appliance|Data|ShuttleAndFindData|Calibration|Marker|StageYPosition #1\t0\n",
      "Appliance|Data|ShuttleAndFindData|Calibration|Marker|StageYPosition #2\t0\n",
      "Appliance|Data|ShuttleAndFindData|Calibration|Marker|StageYPosition #3\t0\n",
      "Appliance|Data|ShuttleAndFindData|Calibration|MicroscopeType\tLM\n",
      "Appliance|Data|ShuttleAndFindData|Calibration|StageOrientation|X\t-1\n",
      "Appliance|Data|ShuttleAndFindData|Calibration|StageOrientation|Y\t1\n",
      "Appliance|Id\tShuttleAndFind:1\n",
      "DisplaySetting|Channel|ChannelUnit|ChannelType\tUnspecified\n",
      "DisplaySetting|Channel|ChannelUnit|FactorI\t1\n",
      "DisplaySetting|Channel|ChannelUnit|OffsetI\t0\n",
      "DisplaySetting|Channel|ChannelUnit|UnitI\tUnknown\n",
      "DisplaySetting|Channel|Color\t#00FF00\n",
      "DisplaySetting|Channel|ColorMode\tColor\n",
      "DisplaySetting|Channel|DyeName\tEGFP\n",
      "DisplaySetting|Channel|Gamma\t1\n",
      "DisplaySetting|Channel|High\t0.1333333333333333\n",
      "DisplaySetting|Channel|Id\t108853132117492280627326639672251045474\n",
      "DisplaySetting|Channel|IsSelected\ttrue\n",
      "DisplaySetting|Channel|Low\t-0\n",
      "DisplaySetting|Channel|Name\tChS1-T2\n",
      "Experiment|AcquisitionBlock|AcquisitionModeSetup|AcquisitionMode\tFrame\n",
      "Experiment|AcquisitionBlock|AcquisitionModeSetup|ApertureDiameter\t4.4099999999999993\n",
      "Experiment|AcquisitionBlock|AcquisitionModeSetup|BiDirectional\ttrue\n",
      "Experiment|AcquisitionBlock|AcquisitionModeSetup|BiDirectionalZ\tfalse\n",
      "Experiment|AcquisitionBlock|AcquisitionModeSetup|BitsPerSample\t8\n",
      "Experiment|AcquisitionBlock|AcquisitionModeSetup|CameraBinning\t1\n",
      "Experiment|AcquisitionBlock|AcquisitionModeSetup|CameraFrameHeight\t1030\n",
      "Experiment|AcquisitionBlock|AcquisitionModeSetup|CameraFrameOffsetX\t0\n",
      "Experiment|AcquisitionBlock|AcquisitionModeSetup|CameraFrameOffsetY\t0\n",
      "Experiment|AcquisitionBlock|AcquisitionModeSetup|CameraFrameWidth\t1300\n",
      "Experiment|AcquisitionBlock|AcquisitionModeSetup|CameraSuperSampling\t0\n",
      "Experiment|AcquisitionBlock|AcquisitionModeSetup|DimensionT\t30\n",
      "Experiment|AcquisitionBlock|AcquisitionModeSetup|DimensionX\t680\n",
      "Experiment|AcquisitionBlock|AcquisitionModeSetup|DimensionY\t280\n",
      "Experiment|AcquisitionBlock|AcquisitionModeSetup|DimensionZ\t1\n",
      "Experiment|AcquisitionBlock|AcquisitionModeSetup|FilterMethod\tAverage\n",
      "Experiment|AcquisitionBlock|AcquisitionModeSetup|FilterMode\tLine\n",
      "Experiment|AcquisitionBlock|AcquisitionModeSetup|FilterSamplingNumber\t2\n",
      "Experiment|AcquisitionBlock|AcquisitionModeSetup|FitFramesizeToRoi\tfalse\n",
      "Experiment|AcquisitionBlock|AcquisitionModeSetup|FocalDistanceLsmTubeLense\t150\n",
      "Experiment|AcquisitionBlock|AcquisitionModeSetup|FocalDistanceScanLense\t52.5\n",
      "Experiment|AcquisitionBlock|AcquisitionModeSetup|FocalDistanceStandardTubeLense\t164.5\n",
      "Experiment|AcquisitionBlock|AcquisitionModeSetup|FocusStabilizer\tfalse\n",
      "Experiment|AcquisitionBlock|AcquisitionModeSetup|HdrEnabled\tfalse\n",
      "Experiment|AcquisitionBlock|AcquisitionModeSetup|HdrImagingMode\t0\n",
      "Experiment|AcquisitionBlock|AcquisitionModeSetup|HdrIntensity\t1\n",
      "Experiment|AcquisitionBlock|AcquisitionModeSetup|HdrNumFrames\t1\n",
      "\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.description': string too long. Expected a string with maximum length 1024, but got a string with length 2152 instead.\", 'type': 'invalid_request_error', 'param': 'tools[0].function.description', 'code': 'string_above_max_length'}}",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mBadRequestError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 21\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mextract\u001B[39m(content):\n\u001B[1;32m     12\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m client\u001B[38;5;241m.\u001B[39mchat\u001B[38;5;241m.\u001B[39mcompletions\u001B[38;5;241m.\u001B[39mcreate(\n\u001B[1;32m     13\u001B[0m         model\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgpt-4-turbo\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     14\u001B[0m         messages\u001B[38;5;241m=\u001B[39m[\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     18\u001B[0m         max_tokens\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5000\u001B[39m\n\u001B[1;32m     19\u001B[0m     )\n\u001B[0;32m---> 21\u001B[0m extract(\u001B[38;5;28minput\u001B[39m)\u001B[38;5;241m.\u001B[39mmodel_dump()\n",
      "Cell \u001B[0;32mIn[8], line 12\u001B[0m, in \u001B[0;36mextract\u001B[0;34m(content)\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mextract\u001B[39m(content):\n\u001B[0;32m---> 12\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m client\u001B[38;5;241m.\u001B[39mchat\u001B[38;5;241m.\u001B[39mcompletions\u001B[38;5;241m.\u001B[39mcreate(\n\u001B[1;32m     13\u001B[0m         model\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgpt-4-turbo\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     14\u001B[0m         messages\u001B[38;5;241m=\u001B[39m[\n\u001B[1;32m     15\u001B[0m             {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrole\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muser\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     16\u001B[0m              \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontent\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPlease genearate the appropriate omexml from this raw metadata. \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28minput\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m}],\n\u001B[1;32m     17\u001B[0m         response_model\u001B[38;5;241m=\u001B[39mOME,\n\u001B[1;32m     18\u001B[0m         max_tokens\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5000\u001B[39m\n\u001B[1;32m     19\u001B[0m     )\n",
      "File \u001B[0;32m~/mambaforge/envs/metagpt/lib/python3.12/site-packages/instructor/patch.py:143\u001B[0m, in \u001B[0;36mpatch.<locals>.new_create_sync\u001B[0;34m(response_model, validation_context, max_retries, strict, *args, **kwargs)\u001B[0m\n\u001B[1;32m    131\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(func)\n\u001B[1;32m    132\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mnew_create_sync\u001B[39m(\n\u001B[1;32m    133\u001B[0m     response_model: \u001B[38;5;28mtype\u001B[39m[T_Model] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    138\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: T_ParamSpec\u001B[38;5;241m.\u001B[39mkwargs,\n\u001B[1;32m    139\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m T_Model:\n\u001B[1;32m    140\u001B[0m     response_model, new_kwargs \u001B[38;5;241m=\u001B[39m handle_response_model(\n\u001B[1;32m    141\u001B[0m         response_model\u001B[38;5;241m=\u001B[39mresponse_model, mode\u001B[38;5;241m=\u001B[39mmode, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[1;32m    142\u001B[0m     )\n\u001B[0;32m--> 143\u001B[0m     response \u001B[38;5;241m=\u001B[39m retry_sync(\n\u001B[1;32m    144\u001B[0m         func\u001B[38;5;241m=\u001B[39mfunc,\n\u001B[1;32m    145\u001B[0m         response_model\u001B[38;5;241m=\u001B[39mresponse_model,\n\u001B[1;32m    146\u001B[0m         validation_context\u001B[38;5;241m=\u001B[39mvalidation_context,\n\u001B[1;32m    147\u001B[0m         max_retries\u001B[38;5;241m=\u001B[39mmax_retries,\n\u001B[1;32m    148\u001B[0m         args\u001B[38;5;241m=\u001B[39margs,\n\u001B[1;32m    149\u001B[0m         strict\u001B[38;5;241m=\u001B[39mstrict,\n\u001B[1;32m    150\u001B[0m         kwargs\u001B[38;5;241m=\u001B[39mnew_kwargs,\n\u001B[1;32m    151\u001B[0m         mode\u001B[38;5;241m=\u001B[39mmode,\n\u001B[1;32m    152\u001B[0m     )\n\u001B[1;32m    153\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m response\n",
      "File \u001B[0;32m~/mambaforge/envs/metagpt/lib/python3.12/site-packages/instructor/retry.py:152\u001B[0m, in \u001B[0;36mretry_sync\u001B[0;34m(func, response_model, validation_context, args, kwargs, max_retries, strict, mode)\u001B[0m\n\u001B[1;32m    149\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmax_retries must be an int or a `tenacity.Retrying` object\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 152\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m attempt \u001B[38;5;129;01min\u001B[39;00m max_retries:\n\u001B[1;32m    153\u001B[0m         \u001B[38;5;28;01mwith\u001B[39;00m attempt:\n\u001B[1;32m    154\u001B[0m             \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[0;32m~/mambaforge/envs/metagpt/lib/python3.12/site-packages/tenacity/__init__.py:347\u001B[0m, in \u001B[0;36mBaseRetrying.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    345\u001B[0m retry_state \u001B[38;5;241m=\u001B[39m RetryCallState(\u001B[38;5;28mself\u001B[39m, fn\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, args\u001B[38;5;241m=\u001B[39m(), kwargs\u001B[38;5;241m=\u001B[39m{})\n\u001B[1;32m    346\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m--> 347\u001B[0m     do \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39miter(retry_state\u001B[38;5;241m=\u001B[39mretry_state)\n\u001B[1;32m    348\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(do, DoAttempt):\n\u001B[1;32m    349\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m AttemptManager(retry_state\u001B[38;5;241m=\u001B[39mretry_state)\n",
      "File \u001B[0;32m~/mambaforge/envs/metagpt/lib/python3.12/site-packages/tenacity/__init__.py:325\u001B[0m, in \u001B[0;36mBaseRetrying.iter\u001B[0;34m(self, retry_state)\u001B[0m\n\u001B[1;32m    323\u001B[0m     retry_exc \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mretry_error_cls(fut)\n\u001B[1;32m    324\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreraise:\n\u001B[0;32m--> 325\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m retry_exc\u001B[38;5;241m.\u001B[39mreraise()\n\u001B[1;32m    326\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m retry_exc \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mfut\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexception\u001B[39;00m()\n\u001B[1;32m    328\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwait:\n",
      "File \u001B[0;32m~/mambaforge/envs/metagpt/lib/python3.12/site-packages/tenacity/__init__.py:158\u001B[0m, in \u001B[0;36mRetryError.reraise\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    156\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mreraise\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m t\u001B[38;5;241m.\u001B[39mNoReturn:\n\u001B[1;32m    157\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlast_attempt\u001B[38;5;241m.\u001B[39mfailed:\n\u001B[0;32m--> 158\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlast_attempt\u001B[38;5;241m.\u001B[39mresult()\n\u001B[1;32m    159\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[0;32m~/mambaforge/envs/metagpt/lib/python3.12/concurrent/futures/_base.py:449\u001B[0m, in \u001B[0;36mFuture.result\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    447\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CancelledError()\n\u001B[1;32m    448\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;241m==\u001B[39m FINISHED:\n\u001B[0;32m--> 449\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__get_result()\n\u001B[1;32m    451\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_condition\u001B[38;5;241m.\u001B[39mwait(timeout)\n\u001B[1;32m    453\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;129;01min\u001B[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001B[0;32m~/mambaforge/envs/metagpt/lib/python3.12/concurrent/futures/_base.py:401\u001B[0m, in \u001B[0;36mFuture.__get_result\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    399\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception:\n\u001B[1;32m    400\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 401\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception\n\u001B[1;32m    402\u001B[0m     \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    403\u001B[0m         \u001B[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001B[39;00m\n\u001B[1;32m    404\u001B[0m         \u001B[38;5;28mself\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/mambaforge/envs/metagpt/lib/python3.12/site-packages/instructor/retry.py:155\u001B[0m, in \u001B[0;36mretry_sync\u001B[0;34m(func, response_model, validation_context, args, kwargs, max_retries, strict, mode)\u001B[0m\n\u001B[1;32m    153\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m attempt:\n\u001B[1;32m    154\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 155\u001B[0m         response \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    156\u001B[0m         stream \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstream\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m    157\u001B[0m         response \u001B[38;5;241m=\u001B[39m update_total_usage(response, total_usage)\n",
      "File \u001B[0;32m~/mambaforge/envs/metagpt/lib/python3.12/site-packages/openai/_utils/_utils.py:277\u001B[0m, in \u001B[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    275\u001B[0m             msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMissing required argument: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mquote(missing[\u001B[38;5;241m0\u001B[39m])\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    276\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(msg)\n\u001B[0;32m--> 277\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/mambaforge/envs/metagpt/lib/python3.12/site-packages/openai/resources/chat/completions.py:579\u001B[0m, in \u001B[0;36mCompletions.create\u001B[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001B[0m\n\u001B[1;32m    548\u001B[0m \u001B[38;5;129m@required_args\u001B[39m([\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m], [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstream\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m    549\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcreate\u001B[39m(\n\u001B[1;32m    550\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    577\u001B[0m     timeout: \u001B[38;5;28mfloat\u001B[39m \u001B[38;5;241m|\u001B[39m httpx\u001B[38;5;241m.\u001B[39mTimeout \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m|\u001B[39m NotGiven \u001B[38;5;241m=\u001B[39m NOT_GIVEN,\n\u001B[1;32m    578\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ChatCompletion \u001B[38;5;241m|\u001B[39m Stream[ChatCompletionChunk]:\n\u001B[0;32m--> 579\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_post(\n\u001B[1;32m    580\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/chat/completions\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    581\u001B[0m         body\u001B[38;5;241m=\u001B[39mmaybe_transform(\n\u001B[1;32m    582\u001B[0m             {\n\u001B[1;32m    583\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m: messages,\n\u001B[1;32m    584\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m: model,\n\u001B[1;32m    585\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfrequency_penalty\u001B[39m\u001B[38;5;124m\"\u001B[39m: frequency_penalty,\n\u001B[1;32m    586\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfunction_call\u001B[39m\u001B[38;5;124m\"\u001B[39m: function_call,\n\u001B[1;32m    587\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfunctions\u001B[39m\u001B[38;5;124m\"\u001B[39m: functions,\n\u001B[1;32m    588\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlogit_bias\u001B[39m\u001B[38;5;124m\"\u001B[39m: logit_bias,\n\u001B[1;32m    589\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlogprobs\u001B[39m\u001B[38;5;124m\"\u001B[39m: logprobs,\n\u001B[1;32m    590\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmax_tokens\u001B[39m\u001B[38;5;124m\"\u001B[39m: max_tokens,\n\u001B[1;32m    591\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mn\u001B[39m\u001B[38;5;124m\"\u001B[39m: n,\n\u001B[1;32m    592\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpresence_penalty\u001B[39m\u001B[38;5;124m\"\u001B[39m: presence_penalty,\n\u001B[1;32m    593\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mresponse_format\u001B[39m\u001B[38;5;124m\"\u001B[39m: response_format,\n\u001B[1;32m    594\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mseed\u001B[39m\u001B[38;5;124m\"\u001B[39m: seed,\n\u001B[1;32m    595\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstop\u001B[39m\u001B[38;5;124m\"\u001B[39m: stop,\n\u001B[1;32m    596\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstream\u001B[39m\u001B[38;5;124m\"\u001B[39m: stream,\n\u001B[1;32m    597\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtemperature\u001B[39m\u001B[38;5;124m\"\u001B[39m: temperature,\n\u001B[1;32m    598\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtool_choice\u001B[39m\u001B[38;5;124m\"\u001B[39m: tool_choice,\n\u001B[1;32m    599\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtools\u001B[39m\u001B[38;5;124m\"\u001B[39m: tools,\n\u001B[1;32m    600\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtop_logprobs\u001B[39m\u001B[38;5;124m\"\u001B[39m: top_logprobs,\n\u001B[1;32m    601\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtop_p\u001B[39m\u001B[38;5;124m\"\u001B[39m: top_p,\n\u001B[1;32m    602\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muser\u001B[39m\u001B[38;5;124m\"\u001B[39m: user,\n\u001B[1;32m    603\u001B[0m             },\n\u001B[1;32m    604\u001B[0m             completion_create_params\u001B[38;5;241m.\u001B[39mCompletionCreateParams,\n\u001B[1;32m    605\u001B[0m         ),\n\u001B[1;32m    606\u001B[0m         options\u001B[38;5;241m=\u001B[39mmake_request_options(\n\u001B[1;32m    607\u001B[0m             extra_headers\u001B[38;5;241m=\u001B[39mextra_headers, extra_query\u001B[38;5;241m=\u001B[39mextra_query, extra_body\u001B[38;5;241m=\u001B[39mextra_body, timeout\u001B[38;5;241m=\u001B[39mtimeout\n\u001B[1;32m    608\u001B[0m         ),\n\u001B[1;32m    609\u001B[0m         cast_to\u001B[38;5;241m=\u001B[39mChatCompletion,\n\u001B[1;32m    610\u001B[0m         stream\u001B[38;5;241m=\u001B[39mstream \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    611\u001B[0m         stream_cls\u001B[38;5;241m=\u001B[39mStream[ChatCompletionChunk],\n\u001B[1;32m    612\u001B[0m     )\n",
      "File \u001B[0;32m~/mambaforge/envs/metagpt/lib/python3.12/site-packages/openai/_base_client.py:1240\u001B[0m, in \u001B[0;36mSyncAPIClient.post\u001B[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001B[0m\n\u001B[1;32m   1226\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpost\u001B[39m(\n\u001B[1;32m   1227\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   1228\u001B[0m     path: \u001B[38;5;28mstr\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1235\u001B[0m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_StreamT] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1236\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ResponseT \u001B[38;5;241m|\u001B[39m _StreamT:\n\u001B[1;32m   1237\u001B[0m     opts \u001B[38;5;241m=\u001B[39m FinalRequestOptions\u001B[38;5;241m.\u001B[39mconstruct(\n\u001B[1;32m   1238\u001B[0m         method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpost\u001B[39m\u001B[38;5;124m\"\u001B[39m, url\u001B[38;5;241m=\u001B[39mpath, json_data\u001B[38;5;241m=\u001B[39mbody, files\u001B[38;5;241m=\u001B[39mto_httpx_files(files), \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions\n\u001B[1;32m   1239\u001B[0m     )\n\u001B[0;32m-> 1240\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(ResponseT, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrequest(cast_to, opts, stream\u001B[38;5;241m=\u001B[39mstream, stream_cls\u001B[38;5;241m=\u001B[39mstream_cls))\n",
      "File \u001B[0;32m~/mambaforge/envs/metagpt/lib/python3.12/site-packages/openai/_base_client.py:921\u001B[0m, in \u001B[0;36mSyncAPIClient.request\u001B[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001B[0m\n\u001B[1;32m    912\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrequest\u001B[39m(\n\u001B[1;32m    913\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    914\u001B[0m     cast_to: Type[ResponseT],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    919\u001B[0m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_StreamT] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    920\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ResponseT \u001B[38;5;241m|\u001B[39m _StreamT:\n\u001B[0;32m--> 921\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_request(\n\u001B[1;32m    922\u001B[0m         cast_to\u001B[38;5;241m=\u001B[39mcast_to,\n\u001B[1;32m    923\u001B[0m         options\u001B[38;5;241m=\u001B[39moptions,\n\u001B[1;32m    924\u001B[0m         stream\u001B[38;5;241m=\u001B[39mstream,\n\u001B[1;32m    925\u001B[0m         stream_cls\u001B[38;5;241m=\u001B[39mstream_cls,\n\u001B[1;32m    926\u001B[0m         remaining_retries\u001B[38;5;241m=\u001B[39mremaining_retries,\n\u001B[1;32m    927\u001B[0m     )\n",
      "File \u001B[0;32m~/mambaforge/envs/metagpt/lib/python3.12/site-packages/openai/_base_client.py:1020\u001B[0m, in \u001B[0;36mSyncAPIClient._request\u001B[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001B[0m\n\u001B[1;32m   1017\u001B[0m         err\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mread()\n\u001B[1;32m   1019\u001B[0m     log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRe-raising status error\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m-> 1020\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_status_error_from_response(err\u001B[38;5;241m.\u001B[39mresponse) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1022\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_process_response(\n\u001B[1;32m   1023\u001B[0m     cast_to\u001B[38;5;241m=\u001B[39mcast_to,\n\u001B[1;32m   1024\u001B[0m     options\u001B[38;5;241m=\u001B[39moptions,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1027\u001B[0m     stream_cls\u001B[38;5;241m=\u001B[39mstream_cls,\n\u001B[1;32m   1028\u001B[0m )\n",
      "\u001B[0;31mBadRequestError\u001B[0m: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.description': string too long. Expected a string with maximum length 1024, but got a string with length 2152 instead.\", 'type': 'invalid_request_error', 'param': 'tools[0].function.description', 'code': 'string_above_max_length'}}"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

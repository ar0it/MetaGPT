{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "with open(\"raw_Metadata_Image8_full.txt\") as f:\n",
    "    metadata = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Please transcribe the following metadata such that it follows the latest ome xml schema.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Sure, please provide the raw metadata such that I can transcribe it.\"},\n",
    "    {\"role\": \"user\", \"content\": metadata}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo-16k\",\n",
    "    messages=messages,\n",
    "    temperature=0,\n",
    "    max_tokens=5000,\n",
    "    top_p=1.0,\n",
    "    frequency_penalty=0.0,\n",
    "    presence_penalty=0.0,\n",
    "    stop=[\"\\\"\\\"\\\"\"]\n",
    ")\n",
    "print(response[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import instructor\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "client = instructor.patch(OpenAI())\n",
    "\n",
    "class UserDetail(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "    \n",
    "user = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    response_model=UserDetail,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Extract Aaron is 25 years old\"},\n",
    "    ],\n",
    ")\n",
    "assert isinstance(user, UserDetail)\n",
    "assert user.name == \"Aaron\"\n",
    "assert user.age == 25\n",
    "print(user.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(user._raw_response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "import instructor\n",
    "\n",
    "# Apply the patch to the OpenAI client\n",
    "# enables response_model keyword\n",
    "client = instructor.patch(OpenAI())\n",
    "\n",
    "class QuestionAnswer(BaseModel):\n",
    "    question: str\n",
    "    answer: str\n",
    "\n",
    "question = \"What is the meaning of life?\"\n",
    "context = \"The according to the devil the meaning of live is to live a life of sin and debauchery.\"\n",
    "\n",
    "qa: QuestionAnswer = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    response_model=QuestionAnswer,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a system that answers questions based on the context. answer exactly what the question asks using the context.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"using the context: {context}\\n\\nAnswer the following question: {question}\",\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "print(qa.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM_Validator validation doesnt seem to work so well for me :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, BeforeValidator\n",
    "from typing_extensions import Annotated\n",
    "from instructor import llm_validator\n",
    "\n",
    "class QuestionAnswerNoEvil(BaseModel):\n",
    "    question: str\n",
    "    answer: Annotated[\n",
    "        str,\n",
    "        BeforeValidator(\n",
    "            llm_validator(\"don't say objectionable things\",client=client, allow_override=True)\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "\n",
    "try:\n",
    "    qa: QuestionAnswerNoEvil = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        response_model=QuestionAnswerNoEvil,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a system that answers questions based on the context. answer exactly what the question asks using the context.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"using the context: {context}\\n\\nAnswer the following question: {question}\",\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "print(qa.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from openai import OpenAI\n",
    "from typing import List\n",
    "from pydantic import Field\n",
    "from typing import Iterable, Optional\n",
    "import instructor\n",
    "\n",
    "client = instructor.patch(OpenAI(), mode=instructor.Mode.FUNCTIONS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Property(BaseModel):\n",
    "    index: str = Field(..., description=\"Monotonically increasing ID\")\n",
    "    key: str = Field(description=\"Must be snake case\")\n",
    "    value: str\n",
    "\n",
    "class Person(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "    birthday: datetime.date\n",
    "    properties: List[Property] = Field(\n",
    "        ...,\n",
    "        description=\"Numbered list of arbitrary extracted properties, should be exactly 2\"\n",
    "    )\n",
    "    \n",
    "class MaybePerson(BaseModel):\n",
    "    result: Optional[Person] = Field(default=None)\n",
    "    error: bool = Field(default=False)\n",
    "    message: Optional[str]\n",
    "    \n",
    "    \n",
    "schema = MaybePerson.model_json_schema()\n",
    "\n",
    "\n",
    "def extract(content):\n",
    "    return client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\",\n",
    "             \"content\": f\"Extract '{content}'\"}],\n",
    "        response_model=MaybePerson\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = f\"Aaron is 25 years old his birthday was yesterday today is {datetime.datetime}. He is friends with Caro whichs brithday was last week. They both like json.\"\n",
    "extract(content).model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = (f'Today is {datetime.datetime}, yesterday Aaron did a lighsheet microscopy experiment with the following metadata. <Image ID=\"Image:0\" Name=\"Image 8 #1\">'\n",
    "           '<Pixels BigEndian=\"false\" DimensionOrder=\"XYCZT\"'\n",
    "           'ID=\"Pixels:0\"'\n",
    "           'PhysicalSizeX=\"0.0992287815904495\"'\n",
    "           'PhysicalSizeXUnit=\"µm\"'\n",
    "           'PhysicalSizeY=\"0.0992287815904495\"'\n",
    "           'PhysicalSizeYUnit=\"µm\"'\n",
    "           'SignificantBits=\"8\"'\n",
    "           'SizeC=\"3\"'\n",
    "           'SizeT=\"30\"'\n",
    "           'SizeX=\"680\"'\n",
    "           'SizeY=\"280\"'\n",
    "           'SizeZ=\"1\"'\n",
    "           'Type=\"uint8\">'\n",
    "           '<Channel AcquisitionMode=\"LaserScanningConfocalMicroscopy\" Color=\"-16711681\" EmissionWavelength=\"646.4456100000001\" EmissionWavelengthUnit=\"nm\" ExcitationWavelength=\"561.0\" ExcitationWavelengthUnit=\"nm\" Fluor=\"mRFP1.2\" ID=\"Channel:0:0\" IlluminationType=\"Epifluorescence\" Name=\"ChS2-T1\" SamplesPerPixel=\"1\">'\n",
    "           '<DetectorSettings Binning=\"1x1\" ID=\"Detector:0:0\"/>'\n",
    "           '<LightPath/>'\n",
    "           '</Channel>'\n",
    "           '<Channel AcquisitionMode=\"LaserScanningConfocalMicroscopy\" Color=\"-1\" ID=\"Channel:0:1\" IlluminationType=\"Epifluorescence\" Name=\"T PMT-T1\" SamplesPerPixel=\"1\">'\n",
    "           '<DetectorSettings Binning=\"1x1\" ID=\"Detector:0:1\"/>'\n",
    "           '<LightPath/>'\n",
    "           '</Channel>'\n",
    "           '<Channel AcquisitionMode=\"LaserScanningConfocalMicroscopy\" Color=\"16711935\" EmissionWavelength=\"530.4922920000002\" EmissionWavelengthUnit=\"nm\" ExcitationWavelength=\"488.00000000000006\" ExcitationWavelengthUnit=\"nm\" Fluor=\"EGFP\" ID=\"Channel:0:2\" IlluminationType=\"Epifluorescence\" Name=\"ChS1-T2\" SamplesPerPixel=\"1\">'\n",
    "           '<DetectorSettings Binning=\"1x1\" ID=\"Detector:1:0\"/>'\n",
    "           '<LightPath/>'\n",
    "           '</Channel>'\n",
    "           '<TiffData FirstC=\"0\" FirstT=\"0\" FirstZ=\"0\" IFD=\"0\" PlaneCount=\"1\">'\n",
    "           '<UUID FileName=\"testetst_Image8_edited_.ome.tif\">urn:uuid:27555393-9fb6-4c14-942c-badbf7548154</UUID>'\n",
    "           '</TiffData>'\n",
    "           '</Pixels>'\n",
    "           '</Image>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ome_types import OME\n",
    "type(OME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ome_types.model import Image\n",
    "from ome_types.model import Experiment\n",
    "from ome_types.model import Experimenter\n",
    "from ome_types.model import Annotation\n",
    "    \n",
    "    \n",
    "schema = OME.model_json_schema()\n",
    "print(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(content):\n",
    "    return client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\",\n",
    "             \"content\": f\"Extract the ome image'{content}'\"}],\n",
    "        response_model=OME\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ome_types import OME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ome_types import OME\n",
    "print(type(OME))\n",
    "def extract(content):\n",
    "    return client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\",\n",
    "             \"content\": f\"Extract '{content}'\"}],\n",
    "        response_model=OME\n",
    "    )\n",
    "\n",
    "content= (\" BitsPerPixel\t8\"\n",
    "          \"DimensionOrder\tXYCZT\"\n",
    "          \"IsInterleaved\tfalse\"\n",
    "          \"IsRGB\tfalse\"\n",
    "          \"LittleEndian\ttrue\"\n",
    "          \"PixelType\tuint8\"\n",
    "          \"Series 0 Name\tImage 8 #1\"\n",
    "          \"SizeC\t3\"\n",
    "          \"SizeT\t30\"\n",
    "          \"SizeX\t680\"\n",
    "          \"SizeY\t280\"\n",
    "          \"SizeZ\t1\")\n",
    "\n",
    "extract(content).model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Iterable, Optional\n",
    "import instructor\n",
    "from openai import OpenAI\n",
    "\n",
    "client = instructor.patch(OpenAI(), mode=instructor.Mode.FUNCTIONS)\n",
    "\n",
    "class Image(BaseModel):\n",
    "    id: str = Field(..., description=\"Unique identifier for the image\")\n",
    "    name: str = Field(..., description=\"Name of the image\")\n",
    "    \n",
    "class OME(BaseModel):\n",
    "    images: List[Image] = Field(..., description=\"List of images in the OME metadata\")\n",
    "\n",
    "print(OME.model_json_schema())\n",
    "class MaybeOME(BaseModel):\n",
    "    result: Optional[OME] = Field(default=None)\n",
    "    error: bool = Field(default=False)\n",
    "    message: Optional[str]\n",
    "    \n",
    "def extract(content):\n",
    "    return client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\",\n",
    "             \"content\": f\"Extract '{content}'\"}],\n",
    "        response_model=OME.model_json_schema()\n",
    "    )\n",
    "\n",
    "content= (\" BitsPerPixel\t8\"\n",
    "          \"DimensionOrder\tXYCZT\"\n",
    "          \"IsInterleaved\tfalse\"\n",
    "          \"IsRGB\tfalse\"\n",
    "          \"LittleEndian\ttrue\"\n",
    "          \"PixelType\tuint8\"\n",
    "          \"Series 0 Name\tImage 8 #1\"\n",
    "          \"SizeC\t3\"\n",
    "          \"SizeT\t30\"\n",
    "          \"SizeX\t680\"\n",
    "          \"SizeY\t280\"\n",
    "          \"SizeZ\t1\")\n",
    "\n",
    "extract(content).model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ome_types import from_xml\n",
    "from ome_types import to_xml\n",
    "from ome_types import to_dict\n",
    "path = \"/out/image8_start_point.ome.xml\"\n",
    "ome = from_xml(path)\n",
    "print(to_xml(ome))\n",
    "print(to_dict(ome))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "\n",
    "from pydantic_compat import field_validator\n",
    "\n",
    "from ome_types._autogenerated.ome_2016_06.dataset import Dataset\n",
    "from ome_types._autogenerated.ome_2016_06.experiment import Experiment\n",
    "from ome_types._autogenerated.ome_2016_06.experimenter import Experimenter\n",
    "from ome_types._autogenerated.ome_2016_06.experimenter_group import (\n",
    "    ExperimenterGroup,\n",
    ")\n",
    "from ome_types._autogenerated.ome_2016_06.folder import Folder\n",
    "from ome_types._autogenerated.ome_2016_06.image import Image\n",
    "from ome_types._autogenerated.ome_2016_06.instrument import Instrument\n",
    "from ome_types._autogenerated.ome_2016_06.plate import Plate\n",
    "from ome_types._autogenerated.ome_2016_06.project import Project\n",
    "from ome_types._autogenerated.ome_2016_06.rights import Rights\n",
    "from ome_types._autogenerated.ome_2016_06.roi import ROI\n",
    "from ome_types._autogenerated.ome_2016_06.screen import Screen\n",
    "from ome_types._autogenerated.ome_2016_06.structured_annotations import (\n",
    "    StructuredAnnotations,\n",
    ")\n",
    "from ome_types._mixins._base_type import OMEType\n",
    "from ome_types._mixins._ome import OMEMixin\n",
    "#from ome_types._mixins._validators import validate_structured_annotations\n",
    "from xsdata_pydantic_basemodel.pydantic_compat import Field\n",
    "\n",
    "__NAMESPACE__ = \"http://www.openmicroscopy.org/Schemas/OME/2016-06\"\n",
    "\n",
    "\n",
    "class OME(OMEMixin, OMEType):\n",
    "    \"\"\"The OME element is a container for all information objects accessible by\n",
    "    OME.\n",
    "\n",
    "    These information objects include descriptions of the imaging experiments\n",
    "    and the people who perform them, descriptions of the microscope, the resulting\n",
    "    images and how they were acquired, the analyses performed on those images,\n",
    "    and the analysis results themselves.\n",
    "    An OME file may contain any or all of this information.\n",
    "    With the creation of the Metadata Only Companion OME-XML and Binary Only OME-TIFF files\n",
    "    the top level OME node has changed slightly.\n",
    "    It can EITHER:\n",
    "    Contain all the previously expected elements\n",
    "    OR:\n",
    "    Contain a single BinaryOnly element that points at\n",
    "    its Metadata Only Companion OME-XML file.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    rights : None | Rights\n",
    "        (The OME Rights).\n",
    "    projects : list[Project]\n",
    "        (The OME Projects).\n",
    "    datasets : list[Dataset]\n",
    "        (The OME Datasets).\n",
    "    folders : list[Folder]\n",
    "        (The OME Folders).\n",
    "    experiments : list[Experiment]\n",
    "        (The OME Experiments).\n",
    "    plates : list[Plate]\n",
    "        (The OME Plates).\n",
    "    screens : list[Screen]\n",
    "        (The OME Screens).\n",
    "    experimenters : list[Experimenter]\n",
    "        (The OME Experimenters).\n",
    "    experimenter_groups : list[ExperimenterGroup]\n",
    "        (The OME ExperimenterGroups).\n",
    "    instruments : list[Instrument]\n",
    "        (The OME Instruments).\n",
    "    images : list[Image]\n",
    "        (The OME Images).\n",
    "    structured_annotations : None | StructuredAnnotations\n",
    "        (The OME StructuredAnnotations).\n",
    "    rois : list[ROI]\n",
    "        (The OME ROIs).\n",
    "    binary_only : None | \"OME.BinaryOnly\"\n",
    "        Pointer to an external metadata file. If this element is present, then no\n",
    "        other metadata may be present in this file, i.e. this file is a place-\n",
    "        holder.\n",
    "    uuid : None | str\n",
    "        This unique identifier is used to keep track of multi part files. It allows\n",
    "        the links between files to survive renaming. While OPTIONAL in the general\n",
    "        case this is REQUIRED in a MetadataOnly Companion to a collection of\n",
    "        BinaryOnly files.\n",
    "    creator : None | str\n",
    "        This is the name of the creating application of the OME-XML and preferably\n",
    "        its full version. e.g \"CompanyName, SoftwareName, V2.6.3456\" This is\n",
    "        optional but we hope it will be set by applications writing out OME-XML\n",
    "        from scratch.\n",
    "    \"\"\"\n",
    "\n",
    "    class Meta:\n",
    "        namespace = \"http://www.openmicroscopy.org/Schemas/OME/2016-06\"\n",
    "\n",
    "    rights: Optional[Rights] = Field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"name\": \"Rights\",\n",
    "            \"type\": \"Element\",\n",
    "        },\n",
    "    )\n",
    "    projects: List[Project] = Field(\n",
    "        default_factory=list,\n",
    "        metadata={\n",
    "            \"name\": \"Project\",\n",
    "            \"type\": \"Element\",\n",
    "        },\n",
    "    )\n",
    "    datasets: List[Dataset] = Field(\n",
    "        default_factory=list,\n",
    "        metadata={\n",
    "            \"name\": \"Dataset\",\n",
    "            \"type\": \"Element\",\n",
    "        },\n",
    "    )\n",
    "    folders: List[Folder] = Field(\n",
    "        default_factory=list,\n",
    "        metadata={\n",
    "            \"name\": \"Folder\",\n",
    "            \"type\": \"Element\",\n",
    "        },\n",
    "    )\n",
    "    experiments: List[Experiment] = Field(\n",
    "        default_factory=list,\n",
    "        metadata={\n",
    "            \"name\": \"Experiment\",\n",
    "            \"type\": \"Element\",\n",
    "        },\n",
    "    )\n",
    "    plates: List[Plate] = Field(\n",
    "        default_factory=list,\n",
    "        metadata={\n",
    "            \"name\": \"Plate\",\n",
    "            \"type\": \"Element\",\n",
    "        },\n",
    "    )\n",
    "    screens: List[Screen] = Field(\n",
    "        default_factory=list,\n",
    "        metadata={\n",
    "            \"name\": \"Screen\",\n",
    "            \"type\": \"Element\",\n",
    "        },\n",
    "    )\n",
    "    experimenters: List[Experimenter] = Field(\n",
    "        default_factory=list,\n",
    "        metadata={\n",
    "            \"name\": \"Experimenter\",\n",
    "            \"type\": \"Element\",\n",
    "        },\n",
    "    )\n",
    "    experimenter_groups: List[ExperimenterGroup] = Field(\n",
    "        default_factory=list,\n",
    "        metadata={\n",
    "            \"name\": \"ExperimenterGroup\",\n",
    "            \"type\": \"Element\",\n",
    "        },\n",
    "    )\n",
    "    instruments: List[Instrument] = Field(\n",
    "        default_factory=list,\n",
    "        metadata={\n",
    "            \"name\": \"Instrument\",\n",
    "            \"type\": \"Element\",\n",
    "        },\n",
    "    )\n",
    "    images: List[Image] = Field(\n",
    "        default_factory=list,\n",
    "        metadata={\n",
    "            \"name\": \"Image\",\n",
    "            \"type\": \"Element\",\n",
    "        },\n",
    "    )\n",
    "    structured_annotations: Optional[StructuredAnnotations] = Field(\n",
    "        metadata={\n",
    "            \"name\": \"StructuredAnnotations\",\n",
    "            \"type\": \"Element\",\n",
    "        },\n",
    "        default_factory=StructuredAnnotations,\n",
    "    )\n",
    "    # FIXME: THIS IS THE PROBLEM TypeError: unhashable type: 'dict'\n",
    "    rois: List[ROI] = Field(\n",
    "        default_factory=list,\n",
    "        metadata={\n",
    "            \"name\": \"ROI\",\n",
    "            \"type\": \"Element\",\n",
    "        },\n",
    "    )\n",
    "    binary_only: Optional[\"OME.BinaryOnly\"] = Field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"name\": \"BinaryOnly\",\n",
    "            \"type\": \"Element\",\n",
    "        },\n",
    "    )\n",
    "    uuid: Optional[str] = Field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"name\": \"UUID\",\n",
    "            \"type\": \"Attribute\",\n",
    "            \"pattern\": r\"(urn:uuid:[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{12})\",\n",
    "        },\n",
    "        regex=\"(urn:uuid:[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{12})\",\n",
    "    )\n",
    "    creator: Optional[str] = Field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"name\": \"Creator\",\n",
    "            \"type\": \"Attribute\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "    class BinaryOnly(OMEType):\n",
    "        \"\"\"\n",
    "        Attributes\n",
    "        ----------\n",
    "        metadata_file : str\n",
    "            Filename of the OME-XML metadata file for this binary data. If the file\n",
    "            cannot be found, a search can be performed based on the UUID.\n",
    "        uuid : str\n",
    "            The unique identifier of another OME-XML block whose metadata describes the\n",
    "            binary data in this file. This UUID is considered authoritative regardless\n",
    "            of mismatches in the filename.\n",
    "        \"\"\"\n",
    "\n",
    "        metadata_file: str = Field(\n",
    "            metadata={\n",
    "                \"name\": \"MetadataFile\",\n",
    "                \"type\": \"Attribute\",\n",
    "                \"required\": True,\n",
    "            }\n",
    "        )\n",
    "        uuid: str = Field(\n",
    "            metadata={\n",
    "                \"name\": \"UUID\",\n",
    "                \"type\": \"Attribute\",\n",
    "                \"required\": True,\n",
    "                \"pattern\": r\"(urn:uuid:[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{12})\",\n",
    "            },\n",
    "            regex=\"(urn:uuid:[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{12})\",\n",
    "        )\n",
    "\n",
    "    #_v_structured_annotations = field_validator(\n",
    "    #    \"structured_annotations\", mode=\"before\"\n",
    "    #)(validate_structured_annotations)\n",
    "\n",
    "\n",
    "BinaryOnly = OME.BinaryOnly\n",
    "\n",
    "OME.model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "\n",
    "from pydantic_compat import field_validator\n",
    "\n",
    "from ome_types._autogenerated.ome_2016_06.annotation_ref import AnnotationRef\n",
    "from ome_types._autogenerated.ome_2016_06.ellipse import Ellipse\n",
    "from ome_types._autogenerated.ome_2016_06.label import Label\n",
    "from ome_types._autogenerated.ome_2016_06.line import Line\n",
    "from ome_types._autogenerated.ome_2016_06.mask import Mask\n",
    "from ome_types._autogenerated.ome_2016_06.point import Point\n",
    "from ome_types._autogenerated.ome_2016_06.polygon import Polygon\n",
    "from ome_types._autogenerated.ome_2016_06.polyline import Polyline\n",
    "from ome_types._autogenerated.ome_2016_06.rectangle import Rectangle\n",
    "from ome_types._mixins._base_type import OMEType\n",
    "from ome_types._mixins._collections import ShapeUnionMixin\n",
    "from ome_types._mixins._validators import validate_shape_union\n",
    "from xsdata_pydantic_basemodel.pydantic_compat import Field\n",
    "\n",
    "__NAMESPACE__ = \"http://www.openmicroscopy.org/Schemas/OME/2016-06\"\n",
    "\n",
    "\n",
    "class ROI(OMEType):\n",
    "    \"\"\"A four dimensional 'Region of Interest'.\n",
    "\n",
    "    If they are not used, and the Image has more than one plane, the\n",
    "    entire set of planes is assumed to be included in the ROI. Multiple\n",
    "    ROIs may be specified.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    union : \"ROI.Union\"\n",
    "        (The ROI Union).\n",
    "    annotation_refs : list[AnnotationRef]\n",
    "        (The ROI AnnotationRefs).\n",
    "    description : None | str\n",
    "        A description for the ROI. [plain-text multi-line string]\n",
    "    id : str\n",
    "        (The ROI ID).\n",
    "    name : None | str\n",
    "        The Name identifies the ROI to the user. [plain-text string]\n",
    "    \"\"\"\n",
    "\n",
    "    class Meta:\n",
    "        namespace = \"http://www.openmicroscopy.org/Schemas/OME/2016-06\"\n",
    "\n",
    "    union: \"ROI.Union\" = Field(\n",
    "        metadata={\n",
    "            \"name\": \"Union\",\n",
    "            \"type\": \"Element\",\n",
    "            \"required\": True,\n",
    "        },\n",
    "        default_factory=lambda: ROI.Union(),\n",
    "    )\n",
    "    annotation_refs: List[AnnotationRef] = Field(\n",
    "        default_factory=list,\n",
    "        metadata={\n",
    "            \"name\": \"AnnotationRef\",\n",
    "            \"type\": \"Element\",\n",
    "        },\n",
    "    )\n",
    "    description: Optional[str] = Field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"name\": \"Description\",\n",
    "            \"type\": \"Element\",\n",
    "            \"white_space\": \"preserve\",\n",
    "        },\n",
    "    )\n",
    "    id: str = Field(\n",
    "        default=\"__auto_sequence__\",\n",
    "        metadata={\n",
    "            \"name\": \"ID\",\n",
    "            \"type\": \"Attribute\",\n",
    "            \"required\": True,\n",
    "            \"pattern\": r\"(urn:lsid:([\\w\\-\\.]+\\.[\\w\\-\\.]+)+:\\S+)|(\\S+)\",\n",
    "        },\n",
    "        regex=\"(urn:lsid:([\\\\w\\\\-\\\\.]+\\\\.[\\\\w\\\\-\\\\.]+)+:\\\\S+)|(\\\\S+)\",\n",
    "    )\n",
    "    name: Optional[str] = Field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"name\": \"Name\",\n",
    "            \"type\": \"Attribute\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "    class Union(ShapeUnionMixin, OMEType):\n",
    "        labels: List[Label] = Field(\n",
    "            default_factory=list,\n",
    "            metadata={\n",
    "                \"name\": \"Label\",\n",
    "                \"type\": \"Element\",\n",
    "            },\n",
    "        )\n",
    "        polygons: List[Polygon] = Field(\n",
    "            default_factory=list,\n",
    "            metadata={\n",
    "                \"name\": \"Polygon\",\n",
    "                \"type\": \"Element\",\n",
    "            },\n",
    "        )\n",
    "        polylines: List[Polyline] = Field(\n",
    "            default_factory=list,\n",
    "            metadata={\n",
    "                \"name\": \"Polyline\",\n",
    "                \"type\": \"Element\",\n",
    "            },\n",
    "        )\n",
    "        lines: List[Line] = Field(\n",
    "            default_factory=list,\n",
    "            metadata={\n",
    "                \"name\": \"Line\",\n",
    "                \"type\": \"Element\",\n",
    "            },\n",
    "        )\n",
    "        ellipses: List[Ellipse] = Field(\n",
    "            default_factory=list,\n",
    "            metadata={\n",
    "                \"name\": \"Ellipse\",\n",
    "                \"type\": \"Element\",\n",
    "            },\n",
    "        )\n",
    "        points: List[Point] = Field(\n",
    "            default_factory=list,\n",
    "            metadata={\n",
    "                \"name\": \"Point\",\n",
    "                \"type\": \"Element\",\n",
    "            },\n",
    "        )\n",
    "        masks: List[Mask] = Field(\n",
    "            default_factory=list,\n",
    "            metadata={\n",
    "                \"name\": \"Mask\",\n",
    "                \"type\": \"Element\",\n",
    "            },\n",
    "        )\n",
    "        rectangles: List[Rectangle] = Field(\n",
    "            default_factory=list,\n",
    "            metadata={\n",
    "                \"name\": \"Rectangle\",\n",
    "                \"type\": \"Element\",\n",
    "            },\n",
    "        )\n",
    "\n",
    "    #_v_shape_union = field_validator(\"union\", mode=\"before\")(validate_shape_union)\n",
    "\n",
    "\n",
    "Union = ROI.Union\n",
    "\n",
    "\n",
    "schema = ROI.model_json_schema()\n",
    "print(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"get_n_day_weather_forecast\",\n",
    "        \"description\": \"Get an N-day weather forecast\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                },\n",
    "                \"format\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                    \"description\": \"The temperature unit to use. Infer this from the users location.\",\n",
    "                },\n",
    "                \"num_days\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"description\": \"The number of days to forecast\",\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"location\", \"format\", \"num_days\"]\n",
    "        },\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ome_types._autogenerated.ome_2016_06 import OME\n",
    "import json\n",
    "\n",
    "schema = OME.model_json_schema()\n",
    "\n",
    "with open('schema.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(schema, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "path = \"/home/aaron/PycharmProjects/MetaGPT/openAI_ome_schema\"\n",
    "with open(path, \"w\") as f:\n",
    "    f.write(json.dumps(openai_schema(OME), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in OME.model_json_schema():\n",
    "    print(t)\n",
    "    if t == \"attribute\":\n",
    "        print(OME.model_json_schema().get(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ome_types._autogenerated.ome_2016_06 import OME\n",
    "from openai import OpenAI\n",
    "import instructor\n",
    "\n",
    "\n",
    "client = instructor.patch(OpenAI(), mode=instructor.Mode.FUNCTIONS)\n",
    "with open(\"/out/raw_Metadata_Image8.txt\") as f:\n",
    "    input = f.read()\n",
    "    \n",
    "def extract(content):\n",
    "    return client.chat.completions.create(\n",
    "        model=\"gpt-4-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\",\n",
    "             \"content\": f\"Please genearate the appropriate omexml from this raw metadata. '{input}'\"}],\n",
    "        response_model=OME\n",
    "    )\n",
    "\n",
    "extract(input).model_dump()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/out/raw_Metadata_Image8.txt\") as f:\n",
    "    input = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from marvin.beta import Application\n",
    "from marvin.beta.assistants import pprint_messages\n",
    "from pydantic import BaseModel\n",
    "from datetime import datetime\n",
    "# --- define a structured state model for the application\n",
    "\n",
    "class ToDo(BaseModel):\n",
    "    name: str\n",
    "    due: datetime\n",
    "    done: bool = False\n",
    "    \n",
    "class ToDoState(BaseModel):\n",
    "    todos: list[ToDo] = []\n",
    "    \n",
    "# --- create the application\n",
    "\n",
    "todo_app = Application(\n",
    "    name=\"ToDo App\", instructions=\"A todo application\", state=ToDoState()\n",
    ")\n",
    "# --- interact with the application\n",
    "# create some todos\n",
    "todo_app.say(\"I need to go to the store tomorrow afternoon\")\n",
    "todo_app.say(\"I need to write documentation for applications at 4\")\n",
    "\n",
    "# finish one of them\n",
    "todo_app.say(\"I finished the docs\")\n",
    "# ask a question\n",
    "todo_app.say(\"Show me my todos\")\n",
    "\n",
    "# print the entire thread\n",
    "\n",
    "pprint_messages(todo_app.default_thread.get_messages())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from marvin.beta import Application\n",
    "import marvin\n",
    "from marvin.beta.assistants import pprint_messages\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "\n",
    "class Prop(BaseModel):\n",
    "    key: str\n",
    "    value: str\n",
    "\n",
    "class MaybeOME(BaseModel):\n",
    "    ome: list[Prop] = []\n",
    "    not_ome: list[Prop] = []\n",
    "    \n",
    "print(MaybeOME.model_json_schema())\n",
    "ome_store = Application(name=\"OME Store\", instruction=\"You will be provided with key value pairs of metadata. Store them in either the ome list or not_ome list depending on if the input is described in the ome xsd schema.\", state=MaybeOME())\n",
    "\n",
    "ome_store.say(input[0])\n",
    "ome_store.say(input[1])\n",
    "pprint_messages(ome_store.default_thread.get_messages())\n",
    "\n",
    "ome_store.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maybe_ome[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import marvin\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class Location(BaseModel):\n",
    "    city: str\n",
    "    state: str\n",
    "\n",
    "location = marvin.cast(\"NYC\", target=Location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "class Prop(BaseModel):\n",
    "    key: str\n",
    "    value: str\n",
    "\n",
    "class MaybeOME(BaseModel):\n",
    "    ome: list[Prop] = []\n",
    "    not_ome: list[Prop] = []\n",
    "\n",
    "print(MaybeOME.model_json_schema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.create(\n",
    "    instructions=\"You are a metadata administrator bot. You will be provided with raw metadata and you will need to transcribe it to ome xml follow the latest ome xsd schema. Use the tool to_ome_xml to transcribe the metadata. Only every respond with the output of the tool.\",\n",
    "    model=\"gpt-4-turbo\",\n",
    "    tools=[\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"to_ome_xml\",\n",
    "                \"description\": \"Creates a valid ome xml from the provided ome xml metadata.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"ome_root\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The root element for the ome xml.\"\n",
    "                        },\n",
    "                    },\n",
    "                    \"required\": [\"ome_root\"]\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "thread = client.beta.threads.create()\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=str(input),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = client.beta.threads.runs.create_and_poll(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id,\n",
    ")\n",
    "\n",
    "if run.status == 'completed':\n",
    "    messages = client.beta.threads.messages.list(\n",
    "        thread_id=thread.id\n",
    "    )\n",
    "    print(messages)\n",
    "else:\n",
    "    print(run.status)\n",
    "\n",
    "# Define the list to store tool outputs\n",
    "tool_outputs = []\n",
    "\n",
    "# Loop through each tool in the required action section\n",
    "for tool in run.required_action.submit_tool_outputs.tool_calls:\n",
    "    if tool.function.name == \"to_ome_xml\":\n",
    "        print(tool.model_dump())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ome_types._autogenerated.ome_2016_06 import OME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_schema(OME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docstring_parser import parse\n",
    "\n",
    "def openai_schema(cls):\n",
    "    \"\"\"\n",
    "    Return the schema in the format of OpenAI's schema as jsonschema\n",
    "\n",
    "    Note:\n",
    "        Its important to add a docstring to describe how to best use this class, it will be included in the description attribute and be part of the prompt.\n",
    "\n",
    "    Returns:\n",
    "        model_json_schema (dict): A dictionary in the format of OpenAI's schema as jsonschema\n",
    "    \"\"\"\n",
    "    schema = cls.model_json_schema()\n",
    "    docstring = parse(cls.__doc__ or \"\")\n",
    "    parameters = {\n",
    "        k: v for k, v in schema.items() if k not in (\"title\", \"description\")\n",
    "    }\n",
    "    for param in docstring.params:\n",
    "        if (name := param.arg_name) in parameters[\"properties\"] and (\n",
    "                description := param.description\n",
    "        ):\n",
    "            if \"description\" not in parameters[\"properties\"][name]:\n",
    "                parameters[\"properties\"][name][\"description\"] = description\n",
    "\n",
    "    parameters[\"required\"] = sorted(\n",
    "        k for k, v in parameters[\"properties\"].items() if \"default\" not in v\n",
    "    )\n",
    "\n",
    "    if \"description\" not in schema:\n",
    "        if docstring.short_description:\n",
    "            schema[\"description\"] = docstring.short_description\n",
    "        else:\n",
    "            schema[\"description\"] = (\n",
    "                f\"Correctly extracted `{cls.__name__}` with all \"\n",
    "                f\"the required parameters with correct types\"\n",
    "            )\n",
    "\n",
    "    return {\n",
    "        \"name\": schema[\"title\"],\n",
    "        \"description\": schema[\"description\"],\n",
    "        \"parameters\": parameters,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T09:22:27.755257Z",
     "start_time": "2024-06-05T09:22:26.541125Z"
    }
   },
   "outputs": [],
   "source": [
    "from marvin.beta import Application\n",
    "from typing import Optional\n",
    "from pydantic import BaseModel, Field\n",
    "import datetime\n",
    "\n",
    "# --- BookMate state models \n",
    "\n",
    "class Book(BaseModel):\n",
    "    title: str\n",
    "    author: str\n",
    "    genre: str\n",
    "    published_year: Optional[int]\n",
    "\n",
    "class UserPreference(BaseModel):\n",
    "    favorite_genres: list[str] = []\n",
    "    favorite_authors: list[str] = []\n",
    "    reading_frequency: Optional[str] = Field(None,\n",
    "                                             description=\"e.g., 'often', 'occasionally', 'rarely'\"\n",
    "                                             )\n",
    "\n",
    "class ReadingHistoryItem(BaseModel):\n",
    "    book: Book\n",
    "    read_date: datetime.date\n",
    "    rating: Optional[int]  = Field(description=\"1-5\")\n",
    "\n",
    "class BookRecommendation(BaseModel):\n",
    "    book: Book\n",
    "    reason: str  = Field(description=\"Why this book is being recommended\")\n",
    "\n",
    "\n",
    "\n",
    "class BookMateState(BaseModel):\n",
    "    user_preferences: UserPreference = Field(default_factory=UserPreference)\n",
    "    reading_history: list[ReadingHistoryItem] = []\n",
    "    recommendations: list[BookRecommendation] = []\n",
    "\n",
    "\n",
    "# --- Build the application\n",
    "app = Application(\n",
    "    name='BookMate',\n",
    "    instructions=\"<as above>\",\n",
    "    state=BookMateState(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T09:22:29.478821Z",
     "start_time": "2024-06-05T09:22:29.476180Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "print(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T08:57:54.969569Z",
     "start_time": "2024-06-05T08:57:54.958414Z"
    }
   },
   "outputs": [],
   "source": [
    "BookMateState().model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T09:35:51.025830Z",
     "start_time": "2024-06-05T09:35:51.019649Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "environ{'PATH': '/home/aaron/mambaforge/envs/metagpt/bin:/home/aaron/mambaforge/condabin:/home/aaron/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/snap/bin',\n",
       "        'LC_MEASUREMENT': 'de_DE.UTF-8',\n",
       "        'XAUTHORITY': '/run/user/1000/.mutter-Xwaylandauth.BOOKO2',\n",
       "        'INVOCATION_ID': '7bb70330a3a741379ef6412c11211a3d',\n",
       "        'XMODIFIERS': '@im=ibus',\n",
       "        'LC_TELEPHONE': 'de_DE.UTF-8',\n",
       "        'XDG_DATA_DIRS': '/usr/share/ubuntu:/usr/local/share/:/usr/share/:/var/lib/snapd/desktop',\n",
       "        'GDMSESSION': 'ubuntu',\n",
       "        'LC_TIME': 'de_DE.UTF-8',\n",
       "        'SNAP_COMMON': '/var/snap/dataspell/common',\n",
       "        'CONDA_DEFAULT_ENV': 'metagpt',\n",
       "        'SNAP_INSTANCE_KEY': '',\n",
       "        'SNAP_USER_COMMON': '/home/aaron/snap/dataspell/common',\n",
       "        'DBUS_SESSION_BUS_ADDRESS': 'unix:path=/run/user/1000/bus',\n",
       "        'SNAP_REVISION': '86',\n",
       "        'XDG_CURRENT_DESKTOP': 'ubuntu:GNOME',\n",
       "        'CONDA_PREFIX': '/home/aaron/mambaforge/envs/metagpt',\n",
       "        'JOURNAL_STREAM': '8:42249',\n",
       "        'LC_PAPER': 'de_DE.UTF-8',\n",
       "        'SESSION_MANAGER': 'local/aaron-notebook:@/tmp/.ICE-unix/1989,unix/aaron-notebook:/tmp/.ICE-unix/1989',\n",
       "        'USERNAME': 'aaron',\n",
       "        'LOGNAME': 'aaron',\n",
       "        'PWD': '/home/aaron/DataspellProjects/MetaGPT',\n",
       "        'MANAGERPID': '1813',\n",
       "        'IM_CONFIG_PHASE': '1',\n",
       "        'SNAP_UID': '1000',\n",
       "        'LANGUAGE': '',\n",
       "        'GJS_DEBUG_TOPICS': 'JS ERROR;JS LOG',\n",
       "        'PYTHONPATH': '/home/aaron/DataspellProjects/MetaGPT',\n",
       "        'SHELL': '/bin/bash',\n",
       "        'LC_ADDRESS': 'de_DE.UTF-8',\n",
       "        'GIO_LAUNCHED_DESKTOP_FILE': '/var/lib/snapd/desktop/applications/dataspell_dataspell.desktop',\n",
       "        'BAMF_DESKTOP_FILE_HINT': '/var/lib/snapd/desktop/applications/dataspell_dataspell.desktop',\n",
       "        'GNOME_DESKTOP_SESSION_ID': 'this-is-deprecated',\n",
       "        'GTK_MODULES': 'gail:atk-bridge',\n",
       "        'LC_ALL': 'en_US.UTF-8',\n",
       "        'SNAP_ARCH': 'amd64',\n",
       "        'CONDA_PROMPT_MODIFIER': '(metagpt) ',\n",
       "        'SYSTEMD_EXEC_PID': '2011',\n",
       "        'XDG_SESSION_DESKTOP': 'ubuntu',\n",
       "        'GNOME_SETUP_DISPLAY': ':1',\n",
       "        'SNAP_LIBRARY_PATH': '/var/lib/snapd/lib/gl:/var/lib/snapd/lib/gl32:/var/lib/snapd/void',\n",
       "        'SSH_AGENT_LAUNCHER': 'gnome-keyring',\n",
       "        'SHLVL': '0',\n",
       "        'SNAP_EUID': '1000',\n",
       "        'LC_IDENTIFICATION': 'de_DE.UTF-8',\n",
       "        'LC_MONETARY': 'de_DE.UTF-8',\n",
       "        'SNAP_NAME': 'dataspell',\n",
       "        'QT_IM_MODULE': 'ibus',\n",
       "        'JAVA_HOME': '/home/aaron/mambaforge/envs/metagpt',\n",
       "        'XDG_CONFIG_DIRS': '/etc/xdg/xdg-ubuntu:/etc/xdg',\n",
       "        'LANG': 'en_US.UTF-8',\n",
       "        'SNAP_INSTANCE_NAME': 'dataspell',\n",
       "        'XDG_SESSION_TYPE': 'wayland',\n",
       "        'SNAP_USER_DATA': '/home/aaron/snap/dataspell/86',\n",
       "        'DISPLAY': ':0',\n",
       "        'SNAP_REEXEC': '',\n",
       "        'WAYLAND_DISPLAY': 'wayland-0',\n",
       "        'SNAP_VERSION': '2024.1.1',\n",
       "        'LC_NAME': 'de_DE.UTF-8',\n",
       "        'CONDA_SHLVL': '1',\n",
       "        'XDG_SESSION_CLASS': 'user',\n",
       "        '_': '/usr/bin/gnome-session',\n",
       "        'SNAP_DATA': '/var/snap/dataspell/86',\n",
       "        'JAVA_LD_LIBRARY_PATH': '/home/aaron/mambaforge/envs/metagpt/jre/lib/amd64/server',\n",
       "        'DESKTOP_SESSION': 'ubuntu',\n",
       "        'SNAP': '/snap/dataspell/86',\n",
       "        'USER': 'aaron',\n",
       "        'SNAP_REAL_HOME': '/home/aaron',\n",
       "        'XDG_MENU_PREFIX': 'gnome-',\n",
       "        'GIO_LAUNCHED_DESKTOP_FILE_PID': '71465',\n",
       "        'QT_ACCESSIBILITY': '1',\n",
       "        'LC_NUMERIC': 'de_DE.UTF-8',\n",
       "        'GJS_DEBUG_OUTPUT': 'stderr',\n",
       "        'SSH_AUTH_SOCK': '/run/user/1000/keyring/ssh',\n",
       "        'GNOME_SHELL_SESSION_MODE': 'ubuntu',\n",
       "        'SNAP_CONTEXT': 'CtSh3jHKH9FxE_LZKbWEiWarK80BpcGf8voTvJ8XRfXORvKUAVnK',\n",
       "        'XDG_RUNTIME_DIR': '/run/user/1000',\n",
       "        'SNAP_COOKIE': 'CtSh3jHKH9FxE_LZKbWEiWarK80BpcGf8voTvJ8XRfXORvKUAVnK',\n",
       "        'HOME': '/home/aaron',\n",
       "        'JPY_SESSION_NAME': 'pydantic_tests.ipynb',\n",
       "        'JPY_PARENT_PID': '71921',\n",
       "        'PYDEVD_USE_FRAME_EVAL': 'NO',\n",
       "        'TERM': 'xterm-color',\n",
       "        'CLICOLOR': '1',\n",
       "        'FORCE_COLOR': '1',\n",
       "        'CLICOLOR_FORCE': '1',\n",
       "        'PAGER': 'cat',\n",
       "        'GIT_PAGER': 'cat',\n",
       "        'MPLBACKEND': 'module://matplotlib_inline.backend_inline'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T09:32:22.439428Z",
     "start_time": "2024-06-05T09:32:21.806380Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sk-proj-jvcs6Y8lUhXsySt7b4rGT3BlbkFJgGf56k0FcmaMlCovjs8N'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "client.api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T09:22:31.767690Z",
     "start_time": "2024-06-05T09:22:31.373877Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "OpenAI API key not found! Marvin will not work properly without it.\n\nYou can either:\n    1. Set the `MARVIN_OPENAI_API_KEY` or `OPENAI_API_KEY` environment variables\n    2. Set `marvin.settings.openai.api_key` in your code (not recommended for production)\n    \nIf you do not have an OpenAI API key, you can create one at https://platform.openai.com/api-keys.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msay\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mI like reading science fiction books\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m app\u001b[38;5;241m.\u001b[39msay(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI read \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe Martian\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m by Andy Weir last week and rated it 5 stars\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/mambaforge/envs/metagpt/lib/python3.9/site-packages/marvin/utilities/asyncio.py:193\u001b[0m, in \u001b[0;36mexpose_sync_method.<locals>.decorator.<locals>.sync_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(async_method)\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msync_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    192\u001b[0m     coro \u001b[38;5;241m=\u001b[39m async_method(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 193\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun_sync\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoro\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/metagpt/lib/python3.9/site-packages/marvin/utilities/asyncio.py:104\u001b[0m, in \u001b[0;36mrun_sync\u001b[0;34m(coroutine)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ThreadPoolExecutor() \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m    103\u001b[0m         future \u001b[38;5;241m=\u001b[39m executor\u001b[38;5;241m.\u001b[39msubmit(context\u001b[38;5;241m.\u001b[39mrun, asyncio\u001b[38;5;241m.\u001b[39mrun, coroutine)\n\u001b[0;32m--> 104\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m context\u001b[38;5;241m.\u001b[39mrun(asyncio\u001b[38;5;241m.\u001b[39mrun, coroutine)\n",
      "File \u001b[0;32m~/mambaforge/envs/metagpt/lib/python3.9/concurrent/futures/_base.py:446\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 446\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m~/mambaforge/envs/metagpt/lib/python3.9/concurrent/futures/_base.py:391\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 391\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    393\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    394\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/metagpt/lib/python3.9/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m~/mambaforge/envs/metagpt/lib/python3.9/asyncio/runners.py:44\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m debug \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m         loop\u001b[38;5;241m.\u001b[39mset_debug(debug)\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/mambaforge/envs/metagpt/lib/python3.9/asyncio/base_events.py:647\u001b[0m, in \u001b[0;36mBaseEventLoop.run_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m future\u001b[38;5;241m.\u001b[39mdone():\n\u001b[1;32m    645\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEvent loop stopped before Future completed.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 647\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/metagpt/lib/python3.9/site-packages/marvin/beta/assistants/assistants.py:116\u001b[0m, in \u001b[0;36mAssistant.say_async\u001b[0;34m(self, message, code_interpreter_files, file_search_files, thread, event_handler_class, **run_kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     event_handler_class \u001b[38;5;241m=\u001b[39m default_run_handler_class()\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# post the message\u001b[39;00m\n\u001b[0;32m--> 116\u001b[0m user_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m thread\u001b[38;5;241m.\u001b[39madd_async(\n\u001b[1;32m    117\u001b[0m     message,\n\u001b[1;32m    118\u001b[0m     code_interpreter_files\u001b[38;5;241m=\u001b[39mcode_interpreter_files,\n\u001b[1;32m    119\u001b[0m     file_search_files\u001b[38;5;241m=\u001b[39mfile_search_files,\n\u001b[1;32m    120\u001b[0m )\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmarvin\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbeta\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01massistants\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mruns\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Run\n\u001b[1;32m    124\u001b[0m run \u001b[38;5;241m=\u001b[39m Run(\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;66;03m# provide the user message as part of the run to print\u001b[39;00m\n\u001b[1;32m    126\u001b[0m     messages\u001b[38;5;241m=\u001b[39m[user_message],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrun_kwargs,\n\u001b[1;32m    131\u001b[0m )\n",
      "File \u001b[0;32m~/mambaforge/envs/metagpt/lib/python3.9/site-packages/marvin/beta/assistants/threads.py:74\u001b[0m, in \u001b[0;36mThread.add_async\u001b[0;34m(self, message, role, code_interpreter_files, file_search_files)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;129m@expose_sync_method\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madd\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd_async\u001b[39m(\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     69\u001b[0m     file_search_files: Optional[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     70\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Message:\n\u001b[1;32m     71\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m    Add a user message to the thread.\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 74\u001b[0m     client \u001b[38;5;241m=\u001b[39m \u001b[43mmarvin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutilities\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_openai_client\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     77\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_async()\n",
      "File \u001b[0;32m~/mambaforge/envs/metagpt/lib/python3.9/site-packages/marvin/utilities/openai.py:44\u001b[0m, in \u001b[0;36mget_openai_client\u001b[0;34m(is_async)\u001b[0m\n\u001b[1;32m     37\u001b[0m     api_key \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     38\u001b[0m         marvin\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39mopenai\u001b[38;5;241m.\u001b[39mapi_key\u001b[38;5;241m.\u001b[39mget_secret_value()\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m marvin\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39mopenai\u001b[38;5;241m.\u001b[39mapi_key\n\u001b[1;32m     40\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     41\u001b[0m     )\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m api_key:\n\u001b[0;32m---> 44\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     45\u001b[0m             inspect\u001b[38;5;241m.\u001b[39mcleandoc(\n\u001b[1;32m     46\u001b[0m \u001b[38;5;250m                \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;124;03m                OpenAI API key not found! Marvin will not work properly without it.\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;124;03m                \u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m                You can either:\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;124;03m                    1. Set the `MARVIN_OPENAI_API_KEY` or `OPENAI_API_KEY` environment variables\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;124;03m                    2. Set `marvin.settings.openai.api_key` in your code (not recommended for production)\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;124;03m                    \u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;124;03m                If you do not have an OpenAI API key, you can create one at https://platform.openai.com/api-keys.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;124;03m                \"\"\"\u001b[39;00m\n\u001b[1;32m     55\u001b[0m             )\n\u001b[1;32m     56\u001b[0m         )\n\u001b[1;32m     58\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[1;32m     59\u001b[0m         api_key\u001b[38;5;241m=\u001b[39mapi_key,\n\u001b[1;32m     60\u001b[0m         organization\u001b[38;5;241m=\u001b[39mmarvin\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39mopenai\u001b[38;5;241m.\u001b[39morganization,\n\u001b[1;32m     61\u001b[0m         base_url\u001b[38;5;241m=\u001b[39mmarvin\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39mopenai\u001b[38;5;241m.\u001b[39mbase_url,\n\u001b[1;32m     62\u001b[0m     )\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# --- Azure OpenAI\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: OpenAI API key not found! Marvin will not work properly without it.\n\nYou can either:\n    1. Set the `MARVIN_OPENAI_API_KEY` or `OPENAI_API_KEY` environment variables\n    2. Set `marvin.settings.openai.api_key` in your code (not recommended for production)\n    \nIf you do not have an OpenAI API key, you can create one at https://platform.openai.com/api-keys."
     ]
    }
   ],
   "source": [
    "app.say(\"I like reading science fiction books\")\n",
    "app.say(\"I read 'The Martian' by Andy Weir last week and rated it 5 stars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T08:58:00.120449Z",
     "start_time": "2024-06-05T08:57:59.457654Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.main.assistants.assistant_MelancholicMarvin import MelancholicMarvin\n",
    "raw_meta_path = \"/out/raw_Metadata_Image8.txt\"\n",
    "with open(raw_meta_path, \"r\") as f:\n",
    "    raw_meta = f.read()\n",
    "melancholic_marvin = MelancholicMarvin()\n",
    "print(melancholic_marvin.assistant.say(f\"Here is the raw metadata {raw_meta} for you to curate.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T09:14:49.367807Z",
     "start_time": "2024-06-05T09:14:49.365120Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value=BookMateState(user_preferences=UserPreference(favorite_genres=[], favorite_authors=[], reading_frequency=None), reading_history=[], recommendations=[])\n"
     ]
    }
   ],
   "source": [
    "print(app.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T06:37:46.547143Z",
     "start_time": "2024-05-25T06:37:46.543584Z"
    }
   },
   "outputs": [],
   "source": [
    "a = [1,2,3]\n",
    "b = [2,3,4]\n",
    "c = set([1,2,312])\n",
    "d = [\"12312\"]\n",
    "list_abc = [a,b,c]\n",
    "[i for i in list_abc+d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T06:21:47.999226Z",
     "start_time": "2024-05-25T06:21:47.996946Z"
    }
   },
   "outputs": [],
   "source": [
    "def flatten(container):\n",
    "    for i in container:\n",
    "        if isinstance(i, (list,tuple,set)):\n",
    "            yield from flatten(i)\n",
    "        else:\n",
    "            yield i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T06:30:06.261865Z",
     "start_time": "2024-05-25T06:30:06.252946Z"
    }
   },
   "outputs": [],
   "source": [
    "list_abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T06:27:10.848630Z",
     "start_time": "2024-05-25T06:27:10.845459Z"
    }
   },
   "outputs": [],
   "source": [
    "flatten(list_abc.append(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T09:14:19.851520Z",
     "start_time": "2024-06-05T09:14:19.849141Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "print(\"test\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

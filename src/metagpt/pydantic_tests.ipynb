{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "with open(\"raw_Metadata_Image8_full.txt\") as f:\n",
    "    metadata = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Please transcribe the following metadata such that it follows the latest ome xml schema.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Sure, please provide the raw metadata such that I can transcribe it.\"},\n",
    "    {\"role\": \"user\", \"content\": metadata}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo-16k\",\n",
    "    messages=messages,\n",
    "    temperature=0,\n",
    "    max_tokens=5000,\n",
    "    top_p=1.0,\n",
    "    frequency_penalty=0.0,\n",
    "    presence_penalty=0.0,\n",
    "    stop=[\"\\\"\\\"\\\"\"]\n",
    ")\n",
    "print(response[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import instructor\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "client = instructor.patch(OpenAI())\n",
    "\n",
    "class UserDetail(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "    \n",
    "user = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    response_model=UserDetail,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Extract Aaron is 25 years old\"},\n",
    "    ],\n",
    ")\n",
    "assert isinstance(user, UserDetail)\n",
    "assert user.name == \"Aaron\"\n",
    "assert user.age == 25\n",
    "print(user.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(user._raw_response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "import instructor\n",
    "\n",
    "# Apply the patch to the OpenAI client\n",
    "# enables response_model keyword\n",
    "client = instructor.patch(OpenAI())\n",
    "\n",
    "class QuestionAnswer(BaseModel):\n",
    "    question: str\n",
    "    answer: str\n",
    "\n",
    "question = \"What is the meaning of life?\"\n",
    "context = \"The according to the devil the meaning of live is to live a life of sin and debauchery.\"\n",
    "\n",
    "qa: QuestionAnswer = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    response_model=QuestionAnswer,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a system that answers questions based on the context. answer exactly what the question asks using the context.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"using the context: {context}\\n\\nAnswer the following question: {question}\",\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "print(qa.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM_Validator validation doesnt seem to work so well for me :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, BeforeValidator\n",
    "from typing_extensions import Annotated\n",
    "from instructor import llm_validator\n",
    "\n",
    "class QuestionAnswerNoEvil(BaseModel):\n",
    "    question: str\n",
    "    answer: Annotated[\n",
    "        str,\n",
    "        BeforeValidator(\n",
    "            llm_validator(\"don't say objectionable things\",client=client, allow_override=True)\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "\n",
    "try:\n",
    "    qa: QuestionAnswerNoEvil = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        response_model=QuestionAnswerNoEvil,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a system that answers questions based on the context. answer exactly what the question asks using the context.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"using the context: {context}\\n\\nAnswer the following question: {question}\",\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "print(qa.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from openai import OpenAI\n",
    "from typing import List\n",
    "from pydantic import Field\n",
    "from typing import Iterable, Optional\n",
    "import instructor\n",
    "\n",
    "client = instructor.patch(OpenAI(), mode=instructor.Mode.FUNCTIONS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Property(BaseModel):\n",
    "    index: str = Field(..., description=\"Monotonically increasing ID\")\n",
    "    key: str = Field(description=\"Must be snake case\")\n",
    "    value: str\n",
    "\n",
    "class Person(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "    birthday: datetime.date\n",
    "    properties: List[Property] = Field(\n",
    "        ...,\n",
    "        description=\"Numbered list of arbitrary extracted properties, should be exactly 2\"\n",
    "    )\n",
    "    \n",
    "class MaybePerson(BaseModel):\n",
    "    result: Optional[Person] = Field(default=None)\n",
    "    error: bool = Field(default=False)\n",
    "    message: Optional[str]\n",
    "    \n",
    "    \n",
    "schema = MaybePerson.model_json_schema()\n",
    "\n",
    "\n",
    "def extract(content):\n",
    "    return client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\",\n",
    "             \"content\": f\"Extract '{content}'\"}],\n",
    "        response_model=MaybePerson\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = f\"Aaron is 25 years old his birthday was yesterday today is {datetime.datetime}. He is friends with Caro whichs brithday was last week. They both like json.\"\n",
    "extract(content).model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = (f'Today is {datetime.datetime}, yesterday Aaron did a lighsheet microscopy experiment with the following metadata. <Image ID=\"Image:0\" Name=\"Image 8 #1\">'\n",
    "           '<Pixels BigEndian=\"false\" DimensionOrder=\"XYCZT\"'\n",
    "           'ID=\"Pixels:0\"'\n",
    "           'PhysicalSizeX=\"0.0992287815904495\"'\n",
    "           'PhysicalSizeXUnit=\"µm\"'\n",
    "           'PhysicalSizeY=\"0.0992287815904495\"'\n",
    "           'PhysicalSizeYUnit=\"µm\"'\n",
    "           'SignificantBits=\"8\"'\n",
    "           'SizeC=\"3\"'\n",
    "           'SizeT=\"30\"'\n",
    "           'SizeX=\"680\"'\n",
    "           'SizeY=\"280\"'\n",
    "           'SizeZ=\"1\"'\n",
    "           'Type=\"uint8\">'\n",
    "           '<Channel AcquisitionMode=\"LaserScanningConfocalMicroscopy\" Color=\"-16711681\" EmissionWavelength=\"646.4456100000001\" EmissionWavelengthUnit=\"nm\" ExcitationWavelength=\"561.0\" ExcitationWavelengthUnit=\"nm\" Fluor=\"mRFP1.2\" ID=\"Channel:0:0\" IlluminationType=\"Epifluorescence\" Name=\"ChS2-T1\" SamplesPerPixel=\"1\">'\n",
    "           '<DetectorSettings Binning=\"1x1\" ID=\"Detector:0:0\"/>'\n",
    "           '<LightPath/>'\n",
    "           '</Channel>'\n",
    "           '<Channel AcquisitionMode=\"LaserScanningConfocalMicroscopy\" Color=\"-1\" ID=\"Channel:0:1\" IlluminationType=\"Epifluorescence\" Name=\"T PMT-T1\" SamplesPerPixel=\"1\">'\n",
    "           '<DetectorSettings Binning=\"1x1\" ID=\"Detector:0:1\"/>'\n",
    "           '<LightPath/>'\n",
    "           '</Channel>'\n",
    "           '<Channel AcquisitionMode=\"LaserScanningConfocalMicroscopy\" Color=\"16711935\" EmissionWavelength=\"530.4922920000002\" EmissionWavelengthUnit=\"nm\" ExcitationWavelength=\"488.00000000000006\" ExcitationWavelengthUnit=\"nm\" Fluor=\"EGFP\" ID=\"Channel:0:2\" IlluminationType=\"Epifluorescence\" Name=\"ChS1-T2\" SamplesPerPixel=\"1\">'\n",
    "           '<DetectorSettings Binning=\"1x1\" ID=\"Detector:1:0\"/>'\n",
    "           '<LightPath/>'\n",
    "           '</Channel>'\n",
    "           '<TiffData FirstC=\"0\" FirstT=\"0\" FirstZ=\"0\" IFD=\"0\" PlaneCount=\"1\">'\n",
    "           '<UUID FileName=\"testetst_Image8_edited_.ome.tif\">urn:uuid:27555393-9fb6-4c14-942c-badbf7548154</UUID>'\n",
    "           '</TiffData>'\n",
    "           '</Pixels>'\n",
    "           '</Image>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ome_types import OME\n",
    "type(OME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ome_types.model import Image\n",
    "from ome_types.model import Experiment\n",
    "from ome_types.model import Experimenter\n",
    "from ome_types.model import Annotation\n",
    "    \n",
    "    \n",
    "schema = OME.model_json_schema()\n",
    "print(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(content):\n",
    "    return client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\",\n",
    "             \"content\": f\"Extract the ome image'{content}'\"}],\n",
    "        response_model=OME\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ome_types import OME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ome_types import OME\n",
    "print(type(OME))\n",
    "def extract(content):\n",
    "    return client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\",\n",
    "             \"content\": f\"Extract '{content}'\"}],\n",
    "        response_model=OME\n",
    "    )\n",
    "\n",
    "content= (\" BitsPerPixel\t8\"\n",
    "          \"DimensionOrder\tXYCZT\"\n",
    "          \"IsInterleaved\tfalse\"\n",
    "          \"IsRGB\tfalse\"\n",
    "          \"LittleEndian\ttrue\"\n",
    "          \"PixelType\tuint8\"\n",
    "          \"Series 0 Name\tImage 8 #1\"\n",
    "          \"SizeC\t3\"\n",
    "          \"SizeT\t30\"\n",
    "          \"SizeX\t680\"\n",
    "          \"SizeY\t280\"\n",
    "          \"SizeZ\t1\")\n",
    "\n",
    "extract(content).model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Iterable, Optional\n",
    "import instructor\n",
    "from openai import OpenAI\n",
    "\n",
    "client = instructor.patch(OpenAI(), mode=instructor.Mode.FUNCTIONS)\n",
    "\n",
    "class Image(BaseModel):\n",
    "    id: str = Field(..., description=\"Unique identifier for the image\")\n",
    "    name: str = Field(..., description=\"Name of the image\")\n",
    "    \n",
    "class OME(BaseModel):\n",
    "    images: List[Image] = Field(..., description=\"List of images in the OME metadata\")\n",
    "\n",
    "print(OME.model_json_schema())\n",
    "class MaybeOME(BaseModel):\n",
    "    result: Optional[OME] = Field(default=None)\n",
    "    error: bool = Field(default=False)\n",
    "    message: Optional[str]\n",
    "    \n",
    "def extract(content):\n",
    "    return client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\",\n",
    "             \"content\": f\"Extract '{content}'\"}],\n",
    "        response_model=OME.model_json_schema()\n",
    "    )\n",
    "\n",
    "content= (\" BitsPerPixel\t8\"\n",
    "          \"DimensionOrder\tXYCZT\"\n",
    "          \"IsInterleaved\tfalse\"\n",
    "          \"IsRGB\tfalse\"\n",
    "          \"LittleEndian\ttrue\"\n",
    "          \"PixelType\tuint8\"\n",
    "          \"Series 0 Name\tImage 8 #1\"\n",
    "          \"SizeC\t3\"\n",
    "          \"SizeT\t30\"\n",
    "          \"SizeX\t680\"\n",
    "          \"SizeY\t280\"\n",
    "          \"SizeZ\t1\")\n",
    "\n",
    "extract(content).model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ome_types import from_xml\n",
    "from ome_types import to_xml\n",
    "from ome_types import to_dict\n",
    "path = \"/out/image8_start_point.ome.xml\"\n",
    "ome = from_xml(path)\n",
    "print(to_xml(ome))\n",
    "print(to_dict(ome))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "\n",
    "from pydantic_compat import field_validator\n",
    "\n",
    "from ome_types._autogenerated.ome_2016_06.dataset import Dataset\n",
    "from ome_types._autogenerated.ome_2016_06.experiment import Experiment\n",
    "from ome_types._autogenerated.ome_2016_06.experimenter import Experimenter\n",
    "from ome_types._autogenerated.ome_2016_06.experimenter_group import (\n",
    "    ExperimenterGroup,\n",
    ")\n",
    "from ome_types._autogenerated.ome_2016_06.folder import Folder\n",
    "from ome_types._autogenerated.ome_2016_06.image import Image\n",
    "from ome_types._autogenerated.ome_2016_06.instrument import Instrument\n",
    "from ome_types._autogenerated.ome_2016_06.plate import Plate\n",
    "from ome_types._autogenerated.ome_2016_06.project import Project\n",
    "from ome_types._autogenerated.ome_2016_06.rights import Rights\n",
    "from ome_types._autogenerated.ome_2016_06.roi import ROI\n",
    "from ome_types._autogenerated.ome_2016_06.screen import Screen\n",
    "from ome_types._autogenerated.ome_2016_06.structured_annotations import (\n",
    "    StructuredAnnotations,\n",
    ")\n",
    "from ome_types._mixins._base_type import OMEType\n",
    "from ome_types._mixins._ome import OMEMixin\n",
    "#from ome_types._mixins._validators import validate_structured_annotations\n",
    "from xsdata_pydantic_basemodel.pydantic_compat import Field\n",
    "\n",
    "__NAMESPACE__ = \"http://www.openmicroscopy.org/Schemas/OME/2016-06\"\n",
    "\n",
    "\n",
    "class OME(OMEMixin, OMEType):\n",
    "    \"\"\"The OME element is a container for all information objects accessible by\n",
    "    OME.\n",
    "\n",
    "    These information objects include descriptions of the imaging experiments\n",
    "    and the people who perform them, descriptions of the microscope, the resulting\n",
    "    images and how they were acquired, the analyses performed on those images,\n",
    "    and the analysis results themselves.\n",
    "    An OME file may contain any or all of this information.\n",
    "    With the creation of the Metadata Only Companion OME-XML and Binary Only OME-TIFF files\n",
    "    the top level OME node has changed slightly.\n",
    "    It can EITHER:\n",
    "    Contain all the previously expected elements\n",
    "    OR:\n",
    "    Contain a single BinaryOnly element that points at\n",
    "    its Metadata Only Companion OME-XML file.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    rights : None | Rights\n",
    "        (The OME Rights).\n",
    "    projects : list[Project]\n",
    "        (The OME Projects).\n",
    "    datasets : list[Dataset]\n",
    "        (The OME Datasets).\n",
    "    folders : list[Folder]\n",
    "        (The OME Folders).\n",
    "    experiments : list[Experiment]\n",
    "        (The OME Experiments).\n",
    "    plates : list[Plate]\n",
    "        (The OME Plates).\n",
    "    screens : list[Screen]\n",
    "        (The OME Screens).\n",
    "    experimenters : list[Experimenter]\n",
    "        (The OME Experimenters).\n",
    "    experimenter_groups : list[ExperimenterGroup]\n",
    "        (The OME ExperimenterGroups).\n",
    "    instruments : list[Instrument]\n",
    "        (The OME Instruments).\n",
    "    images : list[Image]\n",
    "        (The OME Images).\n",
    "    structured_annotations : None | StructuredAnnotations\n",
    "        (The OME StructuredAnnotations).\n",
    "    rois : list[ROI]\n",
    "        (The OME ROIs).\n",
    "    binary_only : None | \"OME.BinaryOnly\"\n",
    "        Pointer to an external metadata file. If this element is present, then no\n",
    "        other metadata may be present in this file, i.e. this file is a place-\n",
    "        holder.\n",
    "    uuid : None | str\n",
    "        This unique identifier is used to keep track of multi part files. It allows\n",
    "        the links between files to survive renaming. While OPTIONAL in the general\n",
    "        case this is REQUIRED in a MetadataOnly Companion to a collection of\n",
    "        BinaryOnly files.\n",
    "    creator : None | str\n",
    "        This is the name of the creating application of the OME-XML and preferably\n",
    "        its full version. e.g \"CompanyName, SoftwareName, V2.6.3456\" This is\n",
    "        optional but we hope it will be set by applications writing out OME-XML\n",
    "        from scratch.\n",
    "    \"\"\"\n",
    "\n",
    "    class Meta:\n",
    "        namespace = \"http://www.openmicroscopy.org/Schemas/OME/2016-06\"\n",
    "\n",
    "    rights: Optional[Rights] = Field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"name\": \"Rights\",\n",
    "            \"type\": \"Element\",\n",
    "        },\n",
    "    )\n",
    "    projects: List[Project] = Field(\n",
    "        default_factory=list,\n",
    "        metadata={\n",
    "            \"name\": \"Project\",\n",
    "            \"type\": \"Element\",\n",
    "        },\n",
    "    )\n",
    "    datasets: List[Dataset] = Field(\n",
    "        default_factory=list,\n",
    "        metadata={\n",
    "            \"name\": \"Dataset\",\n",
    "            \"type\": \"Element\",\n",
    "        },\n",
    "    )\n",
    "    folders: List[Folder] = Field(\n",
    "        default_factory=list,\n",
    "        metadata={\n",
    "            \"name\": \"Folder\",\n",
    "            \"type\": \"Element\",\n",
    "        },\n",
    "    )\n",
    "    experiments: List[Experiment] = Field(\n",
    "        default_factory=list,\n",
    "        metadata={\n",
    "            \"name\": \"Experiment\",\n",
    "            \"type\": \"Element\",\n",
    "        },\n",
    "    )\n",
    "    plates: List[Plate] = Field(\n",
    "        default_factory=list,\n",
    "        metadata={\n",
    "            \"name\": \"Plate\",\n",
    "            \"type\": \"Element\",\n",
    "        },\n",
    "    )\n",
    "    screens: List[Screen] = Field(\n",
    "        default_factory=list,\n",
    "        metadata={\n",
    "            \"name\": \"Screen\",\n",
    "            \"type\": \"Element\",\n",
    "        },\n",
    "    )\n",
    "    experimenters: List[Experimenter] = Field(\n",
    "        default_factory=list,\n",
    "        metadata={\n",
    "            \"name\": \"Experimenter\",\n",
    "            \"type\": \"Element\",\n",
    "        },\n",
    "    )\n",
    "    experimenter_groups: List[ExperimenterGroup] = Field(\n",
    "        default_factory=list,\n",
    "        metadata={\n",
    "            \"name\": \"ExperimenterGroup\",\n",
    "            \"type\": \"Element\",\n",
    "        },\n",
    "    )\n",
    "    instruments: List[Instrument] = Field(\n",
    "        default_factory=list,\n",
    "        metadata={\n",
    "            \"name\": \"Instrument\",\n",
    "            \"type\": \"Element\",\n",
    "        },\n",
    "    )\n",
    "    images: List[Image] = Field(\n",
    "        default_factory=list,\n",
    "        metadata={\n",
    "            \"name\": \"Image\",\n",
    "            \"type\": \"Element\",\n",
    "        },\n",
    "    )\n",
    "    structured_annotations: Optional[StructuredAnnotations] = Field(\n",
    "        metadata={\n",
    "            \"name\": \"StructuredAnnotations\",\n",
    "            \"type\": \"Element\",\n",
    "        },\n",
    "        default_factory=StructuredAnnotations,\n",
    "    )\n",
    "    # FIXME: THIS IS THE PROBLEM TypeError: unhashable type: 'dict'\n",
    "    rois: List[ROI] = Field(\n",
    "        default_factory=list,\n",
    "        metadata={\n",
    "            \"name\": \"ROI\",\n",
    "            \"type\": \"Element\",\n",
    "        },\n",
    "    )\n",
    "    binary_only: Optional[\"OME.BinaryOnly\"] = Field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"name\": \"BinaryOnly\",\n",
    "            \"type\": \"Element\",\n",
    "        },\n",
    "    )\n",
    "    uuid: Optional[str] = Field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"name\": \"UUID\",\n",
    "            \"type\": \"Attribute\",\n",
    "            \"pattern\": r\"(urn:uuid:[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{12})\",\n",
    "        },\n",
    "        regex=\"(urn:uuid:[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{12})\",\n",
    "    )\n",
    "    creator: Optional[str] = Field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"name\": \"Creator\",\n",
    "            \"type\": \"Attribute\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "    class BinaryOnly(OMEType):\n",
    "        \"\"\"\n",
    "        Attributes\n",
    "        ----------\n",
    "        metadata_file : str\n",
    "            Filename of the OME-XML metadata file for this binary data. If the file\n",
    "            cannot be found, a search can be performed based on the UUID.\n",
    "        uuid : str\n",
    "            The unique identifier of another OME-XML block whose metadata describes the\n",
    "            binary data in this file. This UUID is considered authoritative regardless\n",
    "            of mismatches in the filename.\n",
    "        \"\"\"\n",
    "\n",
    "        metadata_file: str = Field(\n",
    "            metadata={\n",
    "                \"name\": \"MetadataFile\",\n",
    "                \"type\": \"Attribute\",\n",
    "                \"required\": True,\n",
    "            }\n",
    "        )\n",
    "        uuid: str = Field(\n",
    "            metadata={\n",
    "                \"name\": \"UUID\",\n",
    "                \"type\": \"Attribute\",\n",
    "                \"required\": True,\n",
    "                \"pattern\": r\"(urn:uuid:[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{12})\",\n",
    "            },\n",
    "            regex=\"(urn:uuid:[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{12})\",\n",
    "        )\n",
    "\n",
    "    #_v_structured_annotations = field_validator(\n",
    "    #    \"structured_annotations\", mode=\"before\"\n",
    "    #)(validate_structured_annotations)\n",
    "\n",
    "\n",
    "BinaryOnly = OME.BinaryOnly\n",
    "\n",
    "OME.model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "\n",
    "from pydantic_compat import field_validator\n",
    "\n",
    "from ome_types._autogenerated.ome_2016_06.annotation_ref import AnnotationRef\n",
    "from ome_types._autogenerated.ome_2016_06.ellipse import Ellipse\n",
    "from ome_types._autogenerated.ome_2016_06.label import Label\n",
    "from ome_types._autogenerated.ome_2016_06.line import Line\n",
    "from ome_types._autogenerated.ome_2016_06.mask import Mask\n",
    "from ome_types._autogenerated.ome_2016_06.point import Point\n",
    "from ome_types._autogenerated.ome_2016_06.polygon import Polygon\n",
    "from ome_types._autogenerated.ome_2016_06.polyline import Polyline\n",
    "from ome_types._autogenerated.ome_2016_06.rectangle import Rectangle\n",
    "from ome_types._mixins._base_type import OMEType\n",
    "from ome_types._mixins._collections import ShapeUnionMixin\n",
    "from ome_types._mixins._validators import validate_shape_union\n",
    "from xsdata_pydantic_basemodel.pydantic_compat import Field\n",
    "\n",
    "__NAMESPACE__ = \"http://www.openmicroscopy.org/Schemas/OME/2016-06\"\n",
    "\n",
    "\n",
    "class ROI(OMEType):\n",
    "    \"\"\"A four dimensional 'Region of Interest'.\n",
    "\n",
    "    If they are not used, and the Image has more than one plane, the\n",
    "    entire set of planes is assumed to be included in the ROI. Multiple\n",
    "    ROIs may be specified.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    union : \"ROI.Union\"\n",
    "        (The ROI Union).\n",
    "    annotation_refs : list[AnnotationRef]\n",
    "        (The ROI AnnotationRefs).\n",
    "    description : None | str\n",
    "        A description for the ROI. [plain-text multi-line string]\n",
    "    id : str\n",
    "        (The ROI ID).\n",
    "    name : None | str\n",
    "        The Name identifies the ROI to the user. [plain-text string]\n",
    "    \"\"\"\n",
    "\n",
    "    class Meta:\n",
    "        namespace = \"http://www.openmicroscopy.org/Schemas/OME/2016-06\"\n",
    "\n",
    "    union: \"ROI.Union\" = Field(\n",
    "        metadata={\n",
    "            \"name\": \"Union\",\n",
    "            \"type\": \"Element\",\n",
    "            \"required\": True,\n",
    "        },\n",
    "        default_factory=lambda: ROI.Union(),\n",
    "    )\n",
    "    annotation_refs: List[AnnotationRef] = Field(\n",
    "        default_factory=list,\n",
    "        metadata={\n",
    "            \"name\": \"AnnotationRef\",\n",
    "            \"type\": \"Element\",\n",
    "        },\n",
    "    )\n",
    "    description: Optional[str] = Field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"name\": \"Description\",\n",
    "            \"type\": \"Element\",\n",
    "            \"white_space\": \"preserve\",\n",
    "        },\n",
    "    )\n",
    "    id: str = Field(\n",
    "        default=\"__auto_sequence__\",\n",
    "        metadata={\n",
    "            \"name\": \"ID\",\n",
    "            \"type\": \"Attribute\",\n",
    "            \"required\": True,\n",
    "            \"pattern\": r\"(urn:lsid:([\\w\\-\\.]+\\.[\\w\\-\\.]+)+:\\S+)|(\\S+)\",\n",
    "        },\n",
    "        regex=\"(urn:lsid:([\\\\w\\\\-\\\\.]+\\\\.[\\\\w\\\\-\\\\.]+)+:\\\\S+)|(\\\\S+)\",\n",
    "    )\n",
    "    name: Optional[str] = Field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"name\": \"Name\",\n",
    "            \"type\": \"Attribute\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "    class Union(ShapeUnionMixin, OMEType):\n",
    "        labels: List[Label] = Field(\n",
    "            default_factory=list,\n",
    "            metadata={\n",
    "                \"name\": \"Label\",\n",
    "                \"type\": \"Element\",\n",
    "            },\n",
    "        )\n",
    "        polygons: List[Polygon] = Field(\n",
    "            default_factory=list,\n",
    "            metadata={\n",
    "                \"name\": \"Polygon\",\n",
    "                \"type\": \"Element\",\n",
    "            },\n",
    "        )\n",
    "        polylines: List[Polyline] = Field(\n",
    "            default_factory=list,\n",
    "            metadata={\n",
    "                \"name\": \"Polyline\",\n",
    "                \"type\": \"Element\",\n",
    "            },\n",
    "        )\n",
    "        lines: List[Line] = Field(\n",
    "            default_factory=list,\n",
    "            metadata={\n",
    "                \"name\": \"Line\",\n",
    "                \"type\": \"Element\",\n",
    "            },\n",
    "        )\n",
    "        ellipses: List[Ellipse] = Field(\n",
    "            default_factory=list,\n",
    "            metadata={\n",
    "                \"name\": \"Ellipse\",\n",
    "                \"type\": \"Element\",\n",
    "            },\n",
    "        )\n",
    "        points: List[Point] = Field(\n",
    "            default_factory=list,\n",
    "            metadata={\n",
    "                \"name\": \"Point\",\n",
    "                \"type\": \"Element\",\n",
    "            },\n",
    "        )\n",
    "        masks: List[Mask] = Field(\n",
    "            default_factory=list,\n",
    "            metadata={\n",
    "                \"name\": \"Mask\",\n",
    "                \"type\": \"Element\",\n",
    "            },\n",
    "        )\n",
    "        rectangles: List[Rectangle] = Field(\n",
    "            default_factory=list,\n",
    "            metadata={\n",
    "                \"name\": \"Rectangle\",\n",
    "                \"type\": \"Element\",\n",
    "            },\n",
    "        )\n",
    "\n",
    "    #_v_shape_union = field_validator(\"union\", mode=\"before\")(validate_shape_union)\n",
    "\n",
    "\n",
    "Union = ROI.Union\n",
    "\n",
    "\n",
    "schema = ROI.model_json_schema()\n",
    "print(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"get_n_day_weather_forecast\",\n",
    "        \"description\": \"Get an N-day weather forecast\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                },\n",
    "                \"format\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                    \"description\": \"The temperature unit to use. Infer this from the users location.\",\n",
    "                },\n",
    "                \"num_days\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"description\": \"The number of days to forecast\",\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"location\", \"format\", \"num_days\"]\n",
    "        },\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ome_types._autogenerated.ome_2016_06 import OME\n",
    "import json\n",
    "\n",
    "schema = OME.model_json_schema()\n",
    "\n",
    "with open('schema.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(schema, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "path = \"/home/aaron/PycharmProjects/MetaGPT/openAI_ome_schema\"\n",
    "with open(path, \"w\") as f:\n",
    "    f.write(json.dumps(openai_schema(OME), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in OME.model_json_schema():\n",
    "    print(t)\n",
    "    if t == \"attribute\":\n",
    "        print(OME.model_json_schema().get(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ome_types._autogenerated.ome_2016_06 import OME\n",
    "from openai import OpenAI\n",
    "import instructor\n",
    "\n",
    "\n",
    "client = instructor.patch(OpenAI(), mode=instructor.Mode.FUNCTIONS)\n",
    "with open(\"/out/raw_Metadata_Image8.txt\") as f:\n",
    "    input = f.read()\n",
    "    \n",
    "def extract(content):\n",
    "    return client.chat.completions.create(\n",
    "        model=\"gpt-4-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\",\n",
    "             \"content\": f\"Please genearate the appropriate omexml from this raw metadata. '{input}'\"}],\n",
    "        response_model=OME\n",
    "    )\n",
    "\n",
    "extract(input).model_dump()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/out/raw_Metadata_Image8.txt\") as f:\n",
    "    input = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from marvin.beta import Application\n",
    "from marvin.beta.assistants import pprint_messages\n",
    "from pydantic import BaseModel\n",
    "from datetime import datetime\n",
    "# --- define a structured state model for the application\n",
    "\n",
    "class ToDo(BaseModel):\n",
    "    name: str\n",
    "    due: datetime\n",
    "    done: bool = False\n",
    "    \n",
    "class ToDoState(BaseModel):\n",
    "    todos: list[ToDo] = []\n",
    "    \n",
    "# --- create the application\n",
    "\n",
    "todo_app = Application(\n",
    "    name=\"ToDo App\", instructions=\"A todo application\", state=ToDoState()\n",
    ")\n",
    "# --- interact with the application\n",
    "# create some todos\n",
    "todo_app.say(\"I need to go to the store tomorrow afternoon\")\n",
    "todo_app.say(\"I need to write documentation for applications at 4\")\n",
    "\n",
    "# finish one of them\n",
    "todo_app.say(\"I finished the docs\")\n",
    "# ask a question\n",
    "todo_app.say(\"Show me my todos\")\n",
    "\n",
    "# print the entire thread\n",
    "\n",
    "pprint_messages(todo_app.default_thread.get_messages())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from marvin.beta import Application\n",
    "import marvin\n",
    "from marvin.beta.assistants import pprint_messages\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "\n",
    "class Prop(BaseModel):\n",
    "    key: str\n",
    "    value: str\n",
    "\n",
    "class MaybeOME(BaseModel):\n",
    "    ome: list[Prop] = []\n",
    "    not_ome: list[Prop] = []\n",
    "    \n",
    "print(MaybeOME.model_json_schema())\n",
    "ome_store = Application(name=\"OME Store\", instruction=\"You will be provided with key value pairs of metadata. Store them in either the ome list or not_ome list depending on if the input is described in the ome xsd schema.\", state=MaybeOME())\n",
    "\n",
    "ome_store.say(input[0])\n",
    "ome_store.say(input[1])\n",
    "pprint_messages(ome_store.default_thread.get_messages())\n",
    "\n",
    "ome_store.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "class Prop(BaseModel):\n",
    "    key: str\n",
    "    value: str\n",
    "\n",
    "class MaybeOME(BaseModel):\n",
    "    ome: list[Prop] = []\n",
    "    not_ome: list[Prop] = []\n",
    "\n",
    "print(MaybeOME.model_json_schema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.create(\n",
    "    instructions=\"You are a metadata administrator bot. You will be provided with raw metadata and you will need to transcribe it to ome xml follow the latest ome xsd schema. Use the tool to_ome_xml to transcribe the metadata. Only every respond with the output of the tool.\",\n",
    "    model=\"gpt-4-turbo\",\n",
    "    tools=[\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"to_ome_xml\",\n",
    "                \"description\": \"Creates a valid ome xml from the provided ome xml metadata.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"ome_root\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The root element for the ome xml.\"\n",
    "                        },\n",
    "                    },\n",
    "                    \"required\": [\"ome_root\"]\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "thread = client.beta.threads.create()\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=str(input),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = client.beta.threads.runs.create_and_poll(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id,\n",
    ")\n",
    "\n",
    "if run.status == 'completed':\n",
    "    messages = client.beta.threads.messages.list(\n",
    "        thread_id=thread.id\n",
    "    )\n",
    "    print(messages)\n",
    "else:\n",
    "    print(run.status)\n",
    "\n",
    "# Define the list to store tool outputs\n",
    "tool_outputs = []\n",
    "\n",
    "# Loop through each tool in the required action section\n",
    "for tool in run.required_action.submit_tool_outputs.tool_calls:\n",
    "    if tool.function.name == \"to_ome_xml\":\n",
    "        print(tool.model_dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to build an app that manages a state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T09:22:27.755257Z",
     "start_time": "2024-06-05T09:22:26.541125Z"
    }
   },
   "outputs": [],
   "source": [
    "from marvin.beta import Application\n",
    "from typing import Optional\n",
    "from pydantic import BaseModel, Field\n",
    "import datetime\n",
    "\n",
    "# --- BookMate state models \n",
    "\n",
    "class Book(BaseModel):\n",
    "    title: str = \"\"\n",
    "    author: str\n",
    "    genre: str\n",
    "    published_year: Optional[int]\n",
    "class Frequency(BaseModel):\n",
    "    often: Optional[bool] = False\n",
    "    occasionally: Optional[bool] = False\n",
    "    rarely: Optional[bool] = False\n",
    "    \n",
    "\n",
    "class UserPreference(BaseModel):\n",
    "\n",
    "    favorite_genres: list[str] = []\n",
    "    favorite_authors: list[str] = []\n",
    "    reading_frequency: Frequency = Field(default_factory=Frequency)\n",
    "\n",
    "class ReadingHistoryItem(BaseModel):\n",
    "    book: Book\n",
    "    read_date: datetime.date\n",
    "    rating: Optional[int]  = Field(description=\"1-5\")\n",
    "\n",
    "class BookRecommendation(BaseModel):\n",
    "    book: Book\n",
    "    reason: str  = Field(description=\"Why this book is being recommended\")\n",
    "\n",
    "\n",
    "\n",
    "class BookMateState(BaseModel):\n",
    "    user_preferences: UserPreference = Field(default_factory=UserPreference)\n",
    "    reading_history: list[ReadingHistoryItem] = []\n",
    "    recommendations: list[BookRecommendation] = []\n",
    "\n",
    "\n",
    "bms = BookMateState()\n",
    "bms.user_preferences.favorite_genres = [\"Science Fiction\", \"Fantasy\"]\n",
    "bms.user_preferences.favorite_authors = [\"Isaac Asimov\", \"Brandon Sanderson\"]\n",
    "bms.user_preferences.reading_frequency.often = True\n",
    "\n",
    "# --- Build the application\n",
    "app = Application(\n",
    "    name='BookMate',\n",
    "    instructions=\"<as above>\",\n",
    "    state=bms,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.state.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BookMateState.model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.say(\"I like to read mystery novels\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Access the OME schema, we can use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ome_types._autogenerated.ome_2016_06 import OME\n",
    "\n",
    "ome1 = OME.model_json_schema()\n",
    "\n",
    "from ome_types import OME\n",
    "ome2 = OME.model_json_schema()\n",
    "\n",
    "print(ome1 == ome2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To translate the BaseModels to the OpenAi Json Schema we can use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docstring_parser import parse\n",
    "\n",
    "def openai_schema(cls):\n",
    "    \"\"\"\n",
    "    Return the schema in the format of OpenAI's schema as jsonschema\n",
    "\n",
    "    Note:\n",
    "        Its important to add a docstring to describe how to best use this class, it will be included in the description attribute and be part of the prompt.\n",
    "\n",
    "    Returns:\n",
    "        model_json_schema (dict): A dictionary in the format of OpenAI's schema as jsonschema\n",
    "    \"\"\"\n",
    "    schema = cls.model_json_schema()\n",
    "    docstring = parse(cls.__doc__ or \"\")\n",
    "    parameters = {\n",
    "        k: v for k, v in schema.items() if k not in (\"title\", \"description\")\n",
    "    }\n",
    "    for param in docstring.params:\n",
    "        if (name := param.arg_name) in parameters[\"properties\"] and (\n",
    "                description := param.description\n",
    "        ):\n",
    "            if \"description\" not in parameters[\"properties\"][name]:\n",
    "                parameters[\"properties\"][name][\"description\"] = description\n",
    "\n",
    "    parameters[\"required\"] = sorted(\n",
    "        k for k, v in parameters[\"properties\"].items() if \"default\" not in v\n",
    "    )\n",
    "\n",
    "    if \"description\" not in schema:\n",
    "        if docstring.short_description:\n",
    "            schema[\"description\"] = docstring.short_description\n",
    "        else:\n",
    "            schema[\"description\"] = (\n",
    "                f\"Correctly extracted `{cls.__name__}` with all \"\n",
    "                f\"the required parameters with correct types\"\n",
    "            )\n",
    "\n",
    "    return {\n",
    "        \"name\": schema[\"title\"],\n",
    "        \"description\": schema[\"description\"],\n",
    "        \"parameters\": parameters,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ome_types import OME\n",
    "\n",
    "schema = openai_schema(OME)\n",
    "\n",
    "# write schema to file\n",
    "import json\n",
    "with open(\"OME_schema_OpenAI.json\", \"w\") as f:\n",
    "    json.dump(schema, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempting to create an app which has the ome schema as a state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from marvin.beta import Application\n",
    "from ome_types import OME\n",
    "\n",
    "# --- OME state models\n",
    "\n",
    "# --- Build the application\n",
    "app = Application(\n",
    "    name='OME_Metadata_Store',\n",
    "    instructions=\"Incoming metadata will be provided in raw format,manage the metadata by storing it in the appropriate OME schema.\",\n",
    "    state=OME(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from src.metagpt import BioformatsReader\n",
    "import javabridge\n",
    "import bioformats\n",
    "import ome_types\n",
    "\n",
    "javabridge.start_vm(class_path=bioformats.JARS)\n",
    "\n",
    "image_path = \"/home/aaron/Documents/Projects/MetaGPT/in/images/Image_8.czi\"\n",
    "ome_xml = BioformatsReader.get_omexml_metadata(image_path)\n",
    "ome_raw = BioformatsReader.get_raw_metadata(image_path)\n",
    "ome_tree = BioformatsReader.raw_to_tree(ome_raw)\n",
    "ome_dict = ome_types.to_dict(ome_xml)\n",
    "print(ome_dict)\n",
    "\n",
    "javabridge.kill_vm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ome_types import from_xml\n",
    "from metagpt.utils import from_dict\n",
    "from_xml(ome_xml)\n",
    "from_dict(ome_dict)\n",
    "# TODO: Not same as original ome_xml yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ome_types import OME\n",
    "from ome_types._autogenerated.ome_2016_06 import Image\n",
    "from ome_types._autogenerated.ome_2016_06 import Pixels\n",
    "from marvin.beta import Application\n",
    "\n",
    "state = OME()\n",
    "# add some properties to the state\n",
    "# state.images.append(Image(id=\"Image:0\", name=\"Image 8 #1\", pixels=Pixels(dimension_order=\"XYCZT\", size_c=3, size_t=30, size_x=680, size_y=280, size_z=1, type=\"uint8\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Application(\n",
    "    name=\"OME Metadata Store\",\n",
    "    instructions=\"You are a question answer tool, try to ask questions to fill as much of the state as possible. only ask questions for which the state has a slot.\",\n",
    "    state=state,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.say(\"I have just recorded a microscopy image which i would like to store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.say(\"Title: Image 8, Description: just some cells, Creation Date: today, Format: czi, Dimensions 12, 13, 20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in ome_raw.items():\n",
    "    app.say(f\"Add the metadata stored in the nested dictionary: {ome_tree}\")\n",
    "    app.__exit__()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.chat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to translate from Json to python object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ome_types import OME\n",
    "from deprecated import deprecated\n",
    "ome_root = OME()\n",
    "@deprecated()\n",
    "def from_dict(ome_dict, indent=0, root=ome_root, parent=\"\"):\n",
    "    \"\"\"Application to convert an ome dictionary to an OME object\"\"\"\n",
    "    print(root)\n",
    "    if  isinstance(ome_dict, dict):\n",
    "        # create the approprate Element\n",
    "        if parent != \"\":\n",
    "            child = getattr(root, parent)\n",
    "        else:\n",
    "            child = root\n",
    "        for k, v in ome_dict.items():\n",
    "            print(f\"{'  ' * indent}{k}\")\n",
    "            #child.k = None\n",
    "            from_dict(v, indent+1, child, parent=k)\n",
    "    elif isinstance(ome_dict, list):\n",
    "        for i, j in enumerate(ome_dict):\n",
    "            from_dict(i, indent=indent, root=root, parent=parent)\n",
    "\n",
    "    else:\n",
    "        child = getattr(root, parent)\n",
    "        child = ome_dict\n",
    "        print(f\"{'  ' * indent}{ome_dict}\")\n",
    "\n",
    "from_dict(ome_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ome_types import OME\n",
    "\n",
    "def from_dict(ome_dict):\n",
    "    \"\"\"Convert a dictionary to an OME object.\"\"\"\n",
    "    def set_attributes(obj, data):\n",
    "        for key, value in data.items():\n",
    "            if isinstance(value, dict):\n",
    "                attr = getattr(obj, key, None)\n",
    "                if attr is not None:\n",
    "                    set_attributes(attr, value)\n",
    "                else:\n",
    "                    setattr(obj, key, value)\n",
    "            elif isinstance(value, list):\n",
    "                # Assume the list items are dictionaries that need similar treatment\n",
    "                existing_list = getattr(obj, key, [])\n",
    "                for i, item in enumerate(value):\n",
    "                    if isinstance(item, dict):\n",
    "                        if i < len(existing_list):\n",
    "                            set_attributes(existing_list[i], item)\n",
    "                        else:\n",
    "                            # Handle the case where the list item does not already exist\n",
    "                            existing_list.append(item)\n",
    "                    else:\n",
    "                        existing_list.append(item)\n",
    "                setattr(obj, key, existing_list)\n",
    "            else:\n",
    "                setattr(obj, key, value)\n",
    "    \n",
    "    ome = OME()\n",
    "    set_attributes(ome, ome_dict)\n",
    "    return ome\n",
    "\n",
    "# Example usage:\n",
    "ome_dict = {\n",
    "    'images': [{\n",
    "        'id': 'Image:0',\n",
    "        'name': 'testetst_Image8_edited_.ome.tif',\n",
    "        'description': '',\n",
    "        'pixels': {\n",
    "            'big_endian': False,\n",
    "            'dimension_order': 'XYCZT',\n",
    "            'id': 'Pixels:0',\n",
    "            'interleaved': False,\n",
    "            'physical_size_x': 0.09922878199885109,\n",
    "            'physical_size_x_unit': 'µm',\n",
    "            'physical_size_y': 0.09922878199885109,\n",
    "            'physical_size_y_unit': 'µm',\n",
    "            'significant_bits': 8,\n",
    "            'size_c': 3,\n",
    "            'size_t': 30,\n",
    "            'size_x': 680,\n",
    "            'size_y': 280,\n",
    "            'size_z': 1,\n",
    "            'type': 'uint8',\n",
    "            'channels': [\n",
    "                {'id': 'Channel:0:0', 'samples_per_pixel': 1, 'light_path': {}},\n",
    "                {'id': 'Channel:0:1', 'samples_per_pixel': 1, 'light_path': {}},\n",
    "                {'id': 'Channel:0:2', 'samples_per_pixel': 1, 'light_path': {}}\n",
    "            ],\n",
    "            'metadata_only': {}\n",
    "        }\n",
    "    }]\n",
    "}\n",
    "\n",
    "ome_obj = from_dict(ome_dict)\n",
    "print(ome_obj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_dict(ome_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ome_types\n",
    "from ome_types import OME\n",
    "\n",
    "path = \"in/metadata/testetst_Image8_edited_.ome.xml\"\n",
    "\n",
    "print(ome_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ome_types._autogenerated.ome_2016_06.image import Image\n",
    "\n",
    "Image.model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imagej\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def get_raw_metadata(image_path):\n",
    "    # Initialize ImageJ\n",
    "    ij = imagej.init('sc.fiji:fiji')\n",
    "\n",
    "    # Construct the Bio-Formats Importer command\n",
    "    bio_formats_command = f\"open={image_path} autoscale color_mode=Default display_metadata rois_import=[ROI manager] view=[Metadata only] stack_order=Default\"\n",
    "    \n",
    "    # Run the Bio-Formats Importer\n",
    "    ij.py.run_macro(f\"IJ.run('Bio-Formats Importer', '{bio_formats_command}');\")\n",
    "\n",
    "    # Get the metadata\n",
    "    metadata = ij.WindowManager.getCurrentImage().getStringProperty('Info')\n",
    "\n",
    "    # Split metadata into lines and then key-value pairs\n",
    "    metadata_lines = metadata.split('\\n')\n",
    "    metadata_dict = {}\n",
    "    for line in metadata_lines:\n",
    "        if \": \" in line:\n",
    "            key, value = line.split(\": \", 1)\n",
    "            metadata_dict[key] = value\n",
    "\n",
    "    print(\"Metadata:\", metadata_dict)\n",
    "\n",
    "# Example usage\n",
    "image_path = '/home/aaron/Documents/Projects/MetaGPT/in/images/Image_8.czi'\n",
    "get_raw_metadata(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imagej\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def initialize_imagej():\n",
    "    try:\n",
    "        ij = imagej.init(['sc.fiji:fiji:2.1.0'])\n",
    "        return ij\n",
    "    except Exception as e:\n",
    "        print(\"Error initializing ImageJ:\", e)\n",
    "        return None\n",
    "\n",
    "def get_raw_metadata(image_path, output_csv_path):\n",
    "    # Initialize ImageJ\n",
    "    ij = initialize_imagej()\n",
    "    if ij is None:\n",
    "        print(\"Failed to initialize ImageJ.\")\n",
    "        return\n",
    "\n",
    "    # Construct the Bio-Formats Importer command\n",
    "    bio_formats_command = f\"open={image_path} autoscale color_mode=Default display_metadata rois_import=[ROI manager] view=[Metadata only] stack_order=Default\"\n",
    "    \n",
    "    # Run the Bio-Formats Importer\n",
    "    ij.py.run_macro(f\"IJ.run('Bio-Formats Importer', '{bio_formats_command}');\")\n",
    "\n",
    "    # Get the metadata\n",
    "    imp = ij.WindowManager.getCurrentImage()\n",
    "    if imp is None:\n",
    "        print(\"Failed to open image or extract metadata.\")\n",
    "        return\n",
    "    \n",
    "    metadata = imp.getStringProperty('Info')\n",
    "\n",
    "    # Split metadata into lines and then key-value pairs\n",
    "    metadata_lines = metadata.split('\\n')\n",
    "    metadata_dict = {}\n",
    "    for line in metadata_lines:\n",
    "        if \": \" in line:\n",
    "            key, value = line.split(\": \", 1)\n",
    "            metadata_dict[key] = value\n",
    "\n",
    "    # Convert metadata dictionary to a DataFrame and save as CSV\n",
    "    metadata_df = pd.DataFrame(list(metadata_dict.items()), columns=['Key', 'Value'])\n",
    "    metadata_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "    print(f\"Metadata saved to {output_csv_path}\")\n",
    "\n",
    "# Example usage\n",
    "image_path = '/home/aaron/Documents/Projects/MetaGPT/in/images/Image_8.czi'\n",
    "output_csv_path = '/home/aaron/Desktop/Original Metadata - Image_8.csv'\n",
    "get_raw_metadata(image_path, output_csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "def get_raw_metadata(image_path, output_csv_path):\n",
    "    # Path to Fiji executable\n",
    "    fiji_path = \"/home/aaron/bin/Fiji.app/ImageJ-linux64\"  # Update with your Fiji executable path\n",
    "\n",
    "    # Bio-Formats Importer command\n",
    "    bio_formats_command = f\"open={image_path} autoscale color_mode=Default display_metadata rois_import=[ROI manager] view=[Metadata only] stack_order=Default\"\n",
    "\n",
    "    # Fiji macro command\n",
    "    macro_command = f\"IJ.run('Bio-Formats Importer', '{bio_formats_command}'); IJ.saveAs('Text', '{output_csv_path}');\"\n",
    "\n",
    "    # Run Fiji with the macro\n",
    "    process = subprocess.run([fiji_path, \"--headless\", \"--console\", HelloWorldMacro.ijm], capture_output=True, text=True)\n",
    "    print(process)\n",
    "    if process.returncode == 0:\n",
    "        print(f\"Metadata saved to {output_csv_path}\")\n",
    "    else:\n",
    "        print(f\"Error running Fiji: {process.stderr}\")\n",
    "\n",
    "# Example usage\n",
    "image_path = '/home/aaron/Documents/Projects/MetaGPT/in/images/Image_8.czi'\n",
    "output_csv_path = '/home/aaron/Documents/Projects/MetaGPT/out/Original Metadata - Image_8.csv'\n",
    "get_raw_metadata(image_path, output_csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "def get_raw_metadata(image_path, output_csv_path):\n",
    "    # Path to Fiji executable (update with your actual path)\n",
    "    fiji_path = \"/home/aaron/bin/Fiji.app/ImageJ-linux64\"  # Update with your Fiji executable path\n",
    "\n",
    "    # Construct the Bio-Formats Importer command\n",
    "    bio_formats_command = f\"open={image_path} autoscale color_mode=Default display_metadata rois_import=[ROI manager] view=[Metadata only] stack_order=Default\"\n",
    "    \n",
    "    # Create a temporary macro file\n",
    "    macro_content = f\"\"\"\n",
    "    open(\"{image_path}\");\n",
    "    run(\"Bio-Formats Importer\", \"{bio_formats_command}\");\n",
    "    saveAs(\"Text\", \"{output_csv_path}\");\n",
    "    \"\"\"\n",
    "    \n",
    "    with tempfile.NamedTemporaryFile(delete=False, suffix='.ijm') as macro_file:\n",
    "        macro_file_path = macro_file.name\n",
    "        macro_file.write(macro_content.encode('utf-8'))\n",
    "\n",
    "    try:\n",
    "        # Run Fiji with the macro file\n",
    "        process = subprocess.run([fiji_path, '--headless', '--run', macro_file_path], capture_output=True, text=True)\n",
    "\n",
    "        # Check for errors\n",
    "        if process.returncode == 0:\n",
    "            print(f\"Metadata saved to {output_csv_path}\")\n",
    "        else:\n",
    "            print(f\"Error running Fiji: {process.stderr}\")\n",
    "        print(process)\n",
    "    finally:\n",
    "        # Clean up temporary macro file\n",
    "        os.remove(macro_file_path)\n",
    "\n",
    "# Example usage\n",
    "image_path = '/home/aaron/Documents/Projects/MetaGPT/in/images/Image_8.czi'\n",
    "output_csv_path = '/home/aaron/Documents/Projects/MetaGPT/out/Original Metadata - Image_8.csv'\n",
    "get_raw_metadata(image_path, output_csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imagej\n",
    "\n",
    "def initialize_imagej():\n",
    "    try:\n",
    "        ij = imagej.init()\n",
    "        return ij\n",
    "    except Exception as e:\n",
    "        print(\"Error initializing ImageJ:\", e)\n",
    "        return None\n",
    "\n",
    "def get_version():\n",
    "    ij = initialize_imagej()\n",
    "    if ij is not None:\n",
    "        print(f\"ImageJ version: {ij.getVersion()}\")\n",
    "    else:\n",
    "        print(\"Failed to initialize ImageJ.\")\n",
    "\n",
    "get_version()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import javabridge\n",
    "import bioformats\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize the Java VM\n",
    "javabridge.start_vm(class_path=bioformats.JARS)\n",
    "\n",
    "def extract_raw_metadata(image_path):\n",
    "    # Use Bio-Formats to read the raw metadata\n",
    "    with bioformats.ImageReader(image_path) as reader:\n",
    "        metadata = reader.rdr.getMetadata()\n",
    "\n",
    "    return metadata\n",
    "\n",
    "def save_metadata_to_csv(metadata, output_path):\n",
    "    # Convert the metadata dictionary to a DataFrame\n",
    "    md = javabridge.jutil.jdictionary_to_string_dictionary(metadata)\n",
    "    df = pd.DataFrame(list(md.items()), columns=[\"Key\", \"Value\"])\n",
    "    \n",
    "    # Save the DataFrame to a CSV file\n",
    "    df.to_csv(output_path, index=False)\n",
    "\n",
    "# Specify the image file path and output CSV file path\n",
    "image_path = \"/home/aaron/Documents/Projects/MetaGPT/in/images/Image_8.czi\"\n",
    "output_path = \"/home/aaron/Desktop/Original Metadata - Image_8.csv\"\n",
    "\n",
    "# Extract raw metadata and save to CSV\n",
    "raw_metadata = extract_raw_metadata(image_path)\n",
    "save_metadata_to_csv(raw_metadata, output_path)\n",
    "\n",
    "# Stop the Java VM\n",
    "javabridge.kill_vm()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@deprecated()\n",
    "def get_raw_metadata2(path=None, url=None):\n",
    "    with ImageReader(path=path, url=url, perform_init=False) as rdr:\n",
    "        # Below, \"in\" is a keyword and Rhino's parser is just a little wonky I fear.\n",
    "        #\n",
    "        # It is critical that setGroupFiles be set to false, goodness knows\n",
    "        # why, but if you don't the series count is wrong for flex files.\n",
    "        #\n",
    "        script = \"\"\"\n",
    "            importClass(Packages.loci.common.services.ServiceFactory,\n",
    "                        Packages.loci.formats.services.OMEXMLService,\n",
    "                        Packages.loci.formats['in'].DefaultMetadataOptions,\n",
    "                        Packages.loci.formats['in'].MetadataLevel,\n",
    "                        java.util.Hashtable);\n",
    "            reader.setGroupFiles(false);\n",
    "            reader.setOriginalMetadataPopulated(true);\n",
    "            var service = new ServiceFactory().getInstance(OMEXMLService);\n",
    "            var metadata = service.createOMEXMLMetadata();\n",
    "            reader.setMetadataStore(metadata);\n",
    "            reader.setMetadataOptions(new DefaultMetadataOptions(MetadataLevel.ALL));\n",
    "            reader.setId(path);\n",
    "            var globalMetadata = reader.getGlobalMetadata();\n",
    "            var metadataDict = {};\n",
    "            var keys = globalMetadata.keys();\n",
    "            while (keys.hasMoreElements()) {\n",
    "                var key = keys.nextElement();\n",
    "                metadataDict[key] = globalMetadata.get(key);\n",
    "            }\n",
    "            metadataDict;\n",
    "            \"\"\"\n",
    "        metadata_dict = jutil.run_script(script, dict(path=rdr.path, reader=rdr.rdr))\n",
    "\n",
    "    def java_hashtable_to_dict(java_hashtable):\n",
    "        \"\"\"Convert a Java Hashtable to a Python dictionary.\"\"\"\n",
    "        dict = {}\n",
    "        keys = javabridge.jutil.to_string(java_hashtable)\n",
    "        for key in javabridge.jutil.iterate(java_hashtable.keys()):\n",
    "            dict[key] = javabridge.jutil.to_string(java_hashtable.get(key))\n",
    "        return dict\n",
    "\n",
    "    metadata_dict = java_hashtable_to_dict(metadata_dict)\n",
    "    return metadata_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ome_types._autogenerated.ome_2016_06 import OME\n",
    "mymeta = OME()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from ome_types._autogenerated.ome_2016_06 import Image\n",
    "from ome_types._autogenerated.ome_2016_06 import Pixels\n",
    "img = Image(pixels=Pixels())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Iterator\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "def required_fields(model: type[BaseModel], recursive: bool = False) -> Iterator[str]:\n",
    "    \"\"\"\n",
    "    https://stackoverflow.com/questions/75146792/get-all-required-fields-of-a-nested-pydantic-model\n",
    "    \"\"\"\n",
    "    for name, field in model.model_fields.items():\n",
    "        if not field.is_required():\n",
    "            continue\n",
    "        t = field.annotation\n",
    "        if recursive and isinstance(t, type) and issubclass(t, BaseModel):\n",
    "            yield from required_fields(t, recursive=True)\n",
    "        else:\n",
    "            yield name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('channels', FieldInfo(annotation=List[ome_types._autogenerated.ome_2016_06.channel.Channel], required=False, default_factory=list, json_schema_extra={'name': 'Channel', 'type': 'Element'})), ('bin_data_blocks', FieldInfo(annotation=List[ome_types._autogenerated.ome_2016_06.bin_data.BinData], required=False, default_factory=list, json_schema_extra={'name': 'BinData', 'type': 'Element'})), ('tiff_data_blocks', FieldInfo(annotation=List[ome_types._autogenerated.ome_2016_06.tiff_data.TiffData], required=False, default_factory=list, json_schema_extra={'name': 'TiffData', 'type': 'Element'})), ('metadata_only', FieldInfo(annotation=Union[MetadataOnly, NoneType], required=False, default=None, json_schema_extra={'name': 'MetadataOnly', 'type': 'Element'})), ('planes', FieldInfo(annotation=List[ome_types._autogenerated.ome_2016_06.plane.Plane], required=False, default_factory=list, json_schema_extra={'name': 'Plane', 'type': 'Element'})), ('id', FieldInfo(annotation=str, required=False, default='__auto_sequence__', json_schema_extra={'name': 'ID', 'type': 'Attribute', 'required': True, 'pattern': '(urn:lsid:([\\\\w\\\\-\\\\.]+\\\\.[\\\\w\\\\-\\\\.]+)+:Pixels:\\\\S+)|(Pixels:\\\\S+)'}, metadata=[_PydanticGeneralMetadata(pattern='(urn:lsid:([\\\\w\\\\-\\\\.]+\\\\.[\\\\w\\\\-\\\\.]+)+:Pixels:\\\\S+)|(Pixels:\\\\S+)')])), ('dimension_order', FieldInfo(annotation=Pixels_DimensionOrder, required=True, json_schema_extra={'name': 'DimensionOrder', 'type': 'Attribute', 'required': True})), ('type', FieldInfo(annotation=PixelType, required=True, json_schema_extra={'name': 'Type', 'type': 'Attribute', 'required': True})), ('significant_bits', FieldInfo(annotation=Union[int, NoneType], required=False, default=None, json_schema_extra={'name': 'SignificantBits', 'type': 'Attribute', 'min_inclusive': 1}, metadata=[Ge(ge=1)])), ('interleaved', FieldInfo(annotation=Union[bool, NoneType], required=False, default=None, json_schema_extra={'name': 'Interleaved', 'type': 'Attribute'})), ('big_endian', FieldInfo(annotation=Union[bool, NoneType], required=False, default=None, json_schema_extra={'name': 'BigEndian', 'type': 'Attribute'})), ('size_x', FieldInfo(annotation=int, required=True, json_schema_extra={'name': 'SizeX', 'type': 'Attribute', 'required': True, 'min_inclusive': 1}, metadata=[Ge(ge=1)])), ('size_y', FieldInfo(annotation=int, required=True, json_schema_extra={'name': 'SizeY', 'type': 'Attribute', 'required': True, 'min_inclusive': 1}, metadata=[Ge(ge=1)])), ('size_z', FieldInfo(annotation=int, required=True, json_schema_extra={'name': 'SizeZ', 'type': 'Attribute', 'required': True, 'min_inclusive': 1}, metadata=[Ge(ge=1)])), ('size_c', FieldInfo(annotation=int, required=True, json_schema_extra={'name': 'SizeC', 'type': 'Attribute', 'required': True, 'min_inclusive': 1}, metadata=[Ge(ge=1)])), ('size_t', FieldInfo(annotation=int, required=True, json_schema_extra={'name': 'SizeT', 'type': 'Attribute', 'required': True, 'min_inclusive': 1}, metadata=[Ge(ge=1)])), ('physical_size_x', FieldInfo(annotation=Union[float, NoneType], required=False, default=None, json_schema_extra={'name': 'PhysicalSizeX', 'type': 'Attribute', 'min_exclusive': 0.0}, metadata=[Gt(gt=0.0)])), ('physical_size_x_unit', FieldInfo(annotation=UnitsLength, required=False, default=<UnitsLength.MICROMETER: 'µm'>, json_schema_extra={'name': 'PhysicalSizeXUnit', 'type': 'Attribute'})), ('physical_size_y', FieldInfo(annotation=Union[float, NoneType], required=False, default=None, json_schema_extra={'name': 'PhysicalSizeY', 'type': 'Attribute', 'min_exclusive': 0.0}, metadata=[Gt(gt=0.0)])), ('physical_size_y_unit', FieldInfo(annotation=UnitsLength, required=False, default=<UnitsLength.MICROMETER: 'µm'>, json_schema_extra={'name': 'PhysicalSizeYUnit', 'type': 'Attribute'})), ('physical_size_z', FieldInfo(annotation=Union[float, NoneType], required=False, default=None, json_schema_extra={'name': 'PhysicalSizeZ', 'type': 'Attribute', 'min_exclusive': 0.0}, metadata=[Gt(gt=0.0)])), ('physical_size_z_unit', FieldInfo(annotation=UnitsLength, required=False, default=<UnitsLength.MICROMETER: 'µm'>, json_schema_extra={'name': 'PhysicalSizeZUnit', 'type': 'Attribute'})), ('time_increment', FieldInfo(annotation=Union[float, NoneType], required=False, default=None, json_schema_extra={'name': 'TimeIncrement', 'type': 'Attribute'})), ('time_increment_unit', FieldInfo(annotation=UnitsTime, required=False, default=<UnitsTime.SECOND: 's'>, json_schema_extra={'name': 'TimeIncrementUnit', 'type': 'Attribute'}))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pixels.model_fields.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dimension_order', 'type', 'size_x', 'size_y', 'size_z', 'size_c', 'size_t']\n"
     ]
    }
   ],
   "source": [
    "from ome_types import OME\n",
    "from ome_types._autogenerated.ome_2016_06 import Pixels\n",
    "from ome_types._autogenerated.ome_2016_06 import Image\n",
    "print(list(required_fields(Pixels, recursive=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "assistant = client.beta.assistants.create(\n",
    "    instructions=\"You are a metadata administrator bot. You will be provided with raw metadata and you will need to transcribe it to ome xml follow the latest ome xsd schema. Use the tool to_ome_xml to transcribe the metadata. Only every respond with the output of the tool.\",\n",
    "    model=\"gpt-4-turbo\",\n",
    "    tools=[\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"to_ome_xml\",\n",
    "                \"description\": \"Creates a valid ome xml from the provided ome xml metadata.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"ome_root\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The root element for the ome xml.\"\n",
    "                        },\n",
    "                    },\n",
    "                    \"required\": [\"ome_root\"]\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "thread = client.beta.threads.create()\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=str(input),\n",
    ")\n",
    "\n",
    "run = client.beta.threads.runs.create(max_completion_tokens=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.metagpt import BioformatsReader\n",
    "import javabridge\n",
    "import bioformats\n",
    "import ome_types\n",
    "\n",
    "javabridge.start_vm(class_path=bioformats.JARS)\n",
    "\n",
    "image_path = \"/home/aaron/Documents/Projects/MetaGPT/in/images/testetst_Image8_edited_.ome.tif\"\n",
    "ome_xml = BioformatsReader.get_omexml_metadata(image_path)\n",
    "ome_raw = BioformatsReader.get_raw_metadata(image_path)\n",
    "ome_tree = BioformatsReader.raw_to_tree(ome_raw)\n",
    "ome_dict = ome_types.to_dict(ome_xml)\n",
    "print(ome_dict)\n",
    "\n",
    "javabridge.kill_vm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ome_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.metagpt.assistants.assistant_MelancholicMarvin import MelancholicMarvin\n",
    "\n",
    "ass = MelancholicMarvin()\n",
    "ass.say(\"add this metadata to your state: {ome_tree}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import Type, Dict, Any, List\n",
    "\n",
    "def generate_questionnaire(model: Type[BaseModel]) -> List[Dict[str, Any]]:\n",
    "    schema = model.schema()\n",
    "    properties = schema.get('properties', {})\n",
    "\n",
    "    questionnaire = []\n",
    "    for field, details in properties.items():\n",
    "        question = {\n",
    "            'name': field,\n",
    "            'type': details.get('type', 'string'),  # Default to 'string' if type is missing\n",
    "            'title': details.get('title', field),\n",
    "            'description': details.get('description', ''),\n",
    "            'default': details.get('default'),\n",
    "            'required': field in schema.get('required', [])\n",
    "        }\n",
    "        if details.get('type') == 'object' and 'properties' in details:\n",
    "            sub_model = model.__fields__[field].type_\n",
    "            question['sub_questions'] = generate_questionnaire(sub_model)\n",
    "        questionnaire.append(question)\n",
    "\n",
    "    return questionnaire\n",
    "\n",
    "# Example usage\n",
    "questionnaire = generate_questionnaire(Dog)\n",
    "for question in questionnaire:\n",
    "    print(question)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ome_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ome_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_answer = Application(\n",
    "    name='DataProviderGPT',\n",
    "    instructions=\"You have a dictinoary of raw metadata as your state, your task will be to answer questions about the metadata.\",\n",
    "    state=ome_tree,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.say(\"Does the metadata contain an image?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ome_types._autogenerated.ome_2016_06 import OME\n",
    "from pydantic import BaseModel\n",
    "from typing import Optional\n",
    "from marvin.beta import Application\n",
    "\n",
    "app = Application(\n",
    "    name='OME Metadata Store',\n",
    "    instructions=(\"Incoming metadata will be provided in raw format, that mean a list of key value pairs.!!!\"\n",
    "                  \"Your task  will be to translate these key value pairs to the appropriate OME schema property(try to figure out which porperty is which by looking at the schema and the raw metadata in holistic manner). You will be \"\n",
    "                  \"handed only a part of the ome schema to fill in, to reduce the scope.\"),\n",
    "    state=OME(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OME().model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await app.say_async(f\"here is the metadata to use to fill in the schema: {ome_raw}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.state"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
